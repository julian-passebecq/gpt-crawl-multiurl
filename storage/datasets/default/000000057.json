{
	"title": "API Reference - OpenAI API",
	"url": "https://platform.openai.com/docs/api-reference/files/delete",
	"html": "Overview\nDocumentation\nAPI reference\nLog in\nSign up‍\nSearch\n⌘\nK\nGETTING STARTED\nIntroduction\nAuthentication\nMaking requests\nStreaming\nENDPOINTS\nAudio\nChat\nEmbeddings\nFine-tuning\nFiles\nUpload file\nList files\nRetrieve file\nDelete file\nRetrieve file content\nThe file object\nImages\nModels\nModerations\nBETA\nAssistants\nThreads\nMessages\nRuns\nLEGACY\nCompletions\nIntroduction\n\nYou can interact with the API through HTTP requests from any language, via our official Python bindings, our official Node.js library, or a community-maintained library.\n\nTo install the official Python bindings, run the following command:\n\npip install openai\n\nTo install the official Node.js library, run the following command in your Node.js project directory:\n\nnpm install openai@^4.0.0\nAuthentication\n\nThe OpenAI API uses API keys for authentication. Visit your API Keys page to retrieve the API key you'll use in your requests.\n\nRemember that your API key is a secret! Do not share it with others or expose it in any client-side code (browsers, apps). Production requests must be routed through your own backend server where your API key can be securely loaded from an environment variable or key management service.\n\nAll API requests should include your API key in an Authorization HTTP header as follows:\n\nAuthorization: Bearer OPENAI_API_KEY\nOrganization (optional)\n\nFor users who belong to multiple organizations, you can pass a header to specify which organization is used for an API request. Usage from these API requests will count as usage for the specified organization.\n\nExample curl command:\n\n1\n2\n3\n\ncurl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Organization: YOUR_ORG_ID\"\n\nExample with the openai Python package:\n\n1\n2\n3\n4\n5\n\nfrom openai import OpenAI\n\nclient = OpenAI(\n  organization='YOUR_ORG_ID',\n)\n\nExample with the openai Node.js package:\n\n1\n2\n3\n4\n5\n\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI({\n  organization: 'YOUR_ORG_ID',\n});\n\nOrganization IDs can be found on your Organization settings page.\n\nMaking requests\n\nYou can paste the command below into your terminal to run your first API request. Make sure to replace $OPENAI_API_KEY with your secret API key.\n\n1\n2\n3\n4\n5\n6\n7\n8\n\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n     \"model\": \"gpt-3.5-turbo\",\n     \"messages\": [{\"role\": \"user\", \"content\": \"Say this is a test!\"}],\n     \"temperature\": 0.7\n   }'\n\nThis request queries the gpt-3.5-turbo model (which under the hood points to the latest gpt-3.5-turbo model variant) to complete the text starting with a prompt of \"Say this is a test\". You should get a response back that resembles the following:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n{\n    \"id\": \"chatcmpl-abc123\",\n    \"object\": \"chat.completion\",\n    \"created\": 1677858242,\n    \"model\": \"gpt-3.5-turbo-1106\",\n    \"usage\": {\n        \"prompt_tokens\": 13,\n        \"completion_tokens\": 7,\n        \"total_tokens\": 20\n    },\n    \"choices\": [\n        {\n            \"message\": {\n                \"role\": \"assistant\",\n                \"content\": \"\\n\\nThis is a test!\"\n            },\n            \"logprobs\": null,\n            \"finish_reason\": \"stop\",\n            \"index\": 0\n        }\n    ]\n}\n\nNow that you've generated your first chat completion, let's break down the response object. We can see the finish_reason is stop which means the API returned the full chat completion generated by the model without running into any limits. In the choices list, we only generated a single message but you can set the n parameter to generate multiple messages choices.\n\nStreaming\n\nThe OpenAI API provides the ability to stream responses back to a client in order to allow partial results for certain requests. To achieve this, we follow the Server-sent events standard.\n\nOur official Node and Python libraries handle Server-sent events for you. In Python, a streaming request looks like:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nstream = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}],\n    stream=True,\n)\nfor chunk in stream:\n    if chunk.choices[0].delta.content is not None:\n        print(chunk.choices[0].delta.content, end=\"\")\n\nIn Node / Typescript, a streaming request looks like:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nasync function main() {\n    const stream = await openai.chat.completions.create({\n        model: \"gpt-4\",\n        messages: [{ role: \"user\", content: \"Say this is a test\" }],\n        stream: true,\n    });\n    for await (const chunk of stream) {\n        process.stdout.write(chunk.choices[0]?.delta?.content || \"\");\n    }\n}\n\nmain();\nParsing Server-sent events\n\nParsing Server-sent events is non-trivial and should be done with caution. Simple strategies like splitting by a new line may result in parsing errors. We recommend using existing client libraries when possible.\n\nAudio\n\nLearn how to turn audio into text or text into audio.\n\nRelated guide: Speech to text\n\nCreate speech\n\nPOST\n \nhttps://api.openai.com/v1/audio/speech\n\nGenerates audio from the input text.\n\nRequest body\nmodel\nstring\nRequired\n\nOne of the available TTS models: tts-1 or tts-1-hd\n\ninput\nstring\nRequired\n\nThe text to generate audio for. The maximum length is 4096 characters.\n\nvoice\nstring\nRequired\n\nThe voice to use when generating the audio. Supported voices are alloy, echo, fable, onyx, nova, and shimmer. Previews of the voices are available in the Text to speech guide.\n\nresponse_format\nstring\nOptional\nDefaults to mp3\n\nThe format to audio in. Supported formats are mp3, opus, aac, and flac.\n\nspeed\nnumber\nOptional\nDefaults to 1\n\nThe speed of the generated audio. Select a value from 0.25 to 4.0. 1.0 is the default.\n\nReturns\n\nThe audio file content.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\ncurl https://api.openai.com/v1/audio/speech \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"tts-1\",\n    \"input\": \"The quick brown fox jumped over the lazy dog.\",\n    \"voice\": \"alloy\"\n  }' \\\n  --output speech.mp3\nCreate transcription\n\nPOST\n \nhttps://api.openai.com/v1/audio/transcriptions\n\nTranscribes audio into the input language.\n\nRequest body\nfile\nfile\nRequired\n\nThe audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n\nmodel\nstring\nRequired\n\nID of the model to use. Only whisper-1 is currently available.\n\nlanguage\nstring\nOptional\n\nThe language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency.\n\nprompt\nstring\nOptional\n\nAn optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language.\n\nresponse_format\nstring\nOptional\nDefaults to json\n\nThe format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.\n\ntemperature\nnumber\nOptional\nDefaults to 0\n\nThe sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n\nReturns\n\nThe transcribed text.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode\nCopy‍\n1\n2\n3\n4\n5\n\ncurl https://api.openai.com/v1/audio/transcriptions \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F file=\"@/path/to/file/audio.mp3\" \\\n  -F model=\"whisper-1\"\nResponse\nCopy‍\n1\n2\n3\n\n{\n  \"text\": \"Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that.\"\n}\nCreate translation\n\nPOST\n \nhttps://api.openai.com/v1/audio/translations\n\nTranslates audio into English.\n\nRequest body\nfile\nfile\nRequired\n\nThe audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n\nmodel\nstring\nRequired\n\nID of the model to use. Only whisper-1 is currently available.\n\nprompt\nstring\nOptional\n\nAn optional text to guide the model's style or continue a previous audio segment. The prompt should be in English.\n\nresponse_format\nstring\nOptional\nDefaults to json\n\nThe format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.\n\ntemperature\nnumber\nOptional\nDefaults to 0\n\nThe sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n\nReturns\n\nThe translated text.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode\nCopy‍\n1\n2\n3\n4\n5\n\ncurl https://api.openai.com/v1/audio/translations \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F file=\"@/path/to/file/german.m4a\" \\\n  -F model=\"whisper-1\"\nResponse\nCopy‍\n1\n2\n3\n\n{\n  \"text\": \"Hello, my name is Wolfgang and I come from Germany. Where are you heading today?\"\n}\nChat\n\nGiven a list of messages comprising a conversation, the model will return a response.\n\nRelated guide: Chat Completions\n\nCreate chat completion\n\nPOST\n \nhttps://api.openai.com/v1/chat/completions\n\nCreates a model response for the given chat conversation.\n\nRequest body\nmessages\narray\nRequired\n\nA list of messages comprising the conversation so far. Example Python code.\n\nShow possible types\nmodel\nstring\nRequired\n\nID of the model to use. See the model endpoint compatibility table for details on which models work with the Chat API.\n\nfrequency_penalty\nnumber or null\nOptional\nDefaults to 0\n\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n\nSee more information about frequency and presence penalties.\n\nlogit_bias\nmap\nOptional\nDefaults to null\n\nModify the likelihood of specified tokens appearing in the completion.\n\nAccepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.\n\nlogprobs\nboolean or null\nOptional\nDefaults to false\n\nWhether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message. This option is currently not available on the gpt-4-vision-preview model.\n\ntop_logprobs\ninteger or null\nOptional\n\nAn integer between 0 and 5 specifying the number of most likely tokens to return at each token position, each with an associated log probability. logprobs must be set to true if this parameter is used.\n\nmax_tokens\ninteger or null\nOptional\n\nThe maximum number of tokens that can be generated in the chat completion.\n\nThe total length of input tokens and generated tokens is limited by the model's context length. Example Python code for counting tokens.\n\nn\ninteger or null\nOptional\nDefaults to 1\n\nHow many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep n as 1 to minimize costs.\n\npresence_penalty\nnumber or null\nOptional\nDefaults to 0\n\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n\nSee more information about frequency and presence penalties.\n\nresponse_format\nobject\nOptional\n\nAn object specifying the format that the model must output. Compatible with GPT-4 Turbo and gpt-3.5-turbo-1106.\n\nSetting to { \"type\": \"json_object\" } enables JSON mode, which guarantees the message the model generates is valid JSON.\n\nImportant: when using JSON mode, you must also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if finish_reason=\"length\", which indicates the generation exceeded max_tokens or the conversation exceeded the max context length.\n\nShow properties\nseed\ninteger or null\nOptional\n\nThis feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend.\n\nstop\nstring / array / null\nOptional\nDefaults to null\n\nUp to 4 sequences where the API will stop generating further tokens.\n\nstream\nboolean or null\nOptional\nDefaults to false\n\nIf set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message. Example Python code.\n\ntemperature\nnumber or null\nOptional\nDefaults to 1\n\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or top_p but not both.\n\ntop_p\nnumber or null\nOptional\nDefaults to 1\n\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n\ntools\narray\nOptional\n\nA list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for.\n\nShow properties\ntool_choice\nstring or object\nOptional\n\nControls which (if any) function is called by the model. none means the model will not call a function and instead generates a message. auto means the model can pick between generating a message or calling a function. Specifying a particular function via {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that function.\n\nnone is the default when no functions are present. auto is the default if functions are present.\n\nShow possible types\nuser\nstring\nOptional\n\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.\n\nfunction_call\nDeprecated\nstring or object\nOptional\n\nDeprecated in favor of tool_choice.\n\nControls which (if any) function is called by the model. none means the model will not call a function and instead generates a message. auto means the model can pick between generating a message or calling a function. Specifying a particular function via {\"name\": \"my_function\"} forces the model to call that function.\n\nnone is the default when no functions are present. auto is the default if functions are present.\n\nShow possible types\nfunctions\nDeprecated\narray\nOptional\n\nDeprecated in favor of tools.\n\nA list of functions the model may generate JSON inputs for.\n\nShow properties\nReturns\n\nReturns a chat completion object, or a streamed sequence of chat completion chunk objects if the request is streamed.\n\nDefault‍\nImage input‍\nStreaming‍\nFunctions‍\nLogprobs‍\nExample request\ngpt-3.5-turbo\ngpt-3.5-turbo\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-3.5-turbo\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are a helpful assistant.\"\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"Hello!\"\n      }\n    ]\n  }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\",\n  \"created\": 1677652288,\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"system_fingerprint\": \"fp_44709d6fcb\",\n  \"choices\": [{\n    \"index\": 0,\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"\\n\\nHello there, how may I assist you today?\",\n    },\n    \"logprobs\": null,\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"completion_tokens\": 12,\n    \"total_tokens\": 21\n  }\n}\nThe chat completion object\n\nRepresents a chat completion response returned by model, based on the provided input.\n\nid\nstring\n\nA unique identifier for the chat completion.\n\nchoices\narray\n\nA list of chat completion choices. Can be more than one if n is greater than 1.\n\nShow properties\ncreated\ninteger\n\nThe Unix timestamp (in seconds) of when the chat completion was created.\n\nmodel\nstring\n\nThe model used for the chat completion.\n\nsystem_fingerprint\nstring\n\nThis fingerprint represents the backend configuration that the model runs with.\n\nCan be used in conjunction with the seed request parameter to understand when backend changes have been made that might impact determinism.\n\nobject\nstring\n\nThe object type, which is always chat.completion.\n\nusage\nobject\n\nUsage statistics for the completion request.\n\nShow properties\nThe chat completion object\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\",\n  \"created\": 1677652288,\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"system_fingerprint\": \"fp_44709d6fcb\",\n  \"choices\": [{\n    \"index\": 0,\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"\\n\\nHello there, how may I assist you today?\",\n    },\n    \"logprobs\": null,\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"completion_tokens\": 12,\n    \"total_tokens\": 21\n  }\n}\nThe chat completion chunk object\n\nRepresents a streamed chunk of a chat completion response returned by model, based on the provided input.\n\nid\nstring\n\nA unique identifier for the chat completion. Each chunk has the same ID.\n\nchoices\narray\n\nA list of chat completion choices. Can be more than one if n is greater than 1.\n\nShow properties\ncreated\ninteger\n\nThe Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.\n\nmodel\nstring\n\nThe model to generate the completion.\n\nsystem_fingerprint\nstring\n\nThis fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the seed request parameter to understand when backend changes have been made that might impact determinism.\n\nobject\nstring\n\nThe object type, which is always chat.completion.chunk.\n\nThe chat completion chunk object\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-3.5-turbo-0613\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"logprobs\":null,\"finish_reason\":null}]}\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-3.5-turbo-0613\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{\"content\":\"Hello\"},\"logprobs\":null,\"finish_reason\":null}]}\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-3.5-turbo-0613\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{\"content\":\"!\"},\"logprobs\":null,\"finish_reason\":null}]}\n\n....\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-3.5-turbo-0613\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{\"content\":\" today\"},\"logprobs\":null,\"finish_reason\":null}]}\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-3.5-turbo-0613\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{\"content\":\"?\"},\"logprobs\":null,\"finish_reason\":null}]}\n\n{\"id\":\"chatcmpl-123\",\"object\":\"chat.completion.chunk\",\"created\":1694268190,\"model\":\"gpt-3.5-turbo-0613\", \"system_fingerprint\": \"fp_44709d6fcb\", \"choices\":[{\"index\":0,\"delta\":{},\"logprobs\":null,\"finish_reason\":\"stop\"}]}\nEmbeddings\n\nGet a vector representation of a given input that can be easily consumed by machine learning models and algorithms.\n\nRelated guide: Embeddings\n\nCreate embeddings\n\nPOST\n \nhttps://api.openai.com/v1/embeddings\n\nCreates an embedding vector representing the input text.\n\nRequest body\ninput\nstring or array\nRequired\n\nInput text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for text-embedding-ada-002), cannot be an empty string, and any array must be 2048 dimensions or less. Example Python code for counting tokens.\n\nShow possible types\nmodel\nstring\nRequired\n\nID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.\n\nencoding_format\nstring\nOptional\nDefaults to float\n\nThe format to return the embeddings in. Can be either float or base64.\n\ndimensions\ninteger\nOptional\n\nThe number of dimensions the resulting output embeddings should have. Only supported in text-embedding-3 and later models.\n\nuser\nstring\nOptional\n\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.\n\nReturns\n\nA list of embedding objects.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n\ncurl https://api.openai.com/v1/embeddings \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"input\": \"The food was delicious and the waiter...\",\n    \"model\": \"text-embedding-ada-002\",\n    \"encoding_format\": \"float\"\n  }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"embedding\",\n      \"embedding\": [\n        0.0023064255,\n        -0.009327292,\n        .... (1536 floats total for ada-002)\n        -0.0028842222,\n      ],\n      \"index\": 0\n    }\n  ],\n  \"model\": \"text-embedding-ada-002\",\n  \"usage\": {\n    \"prompt_tokens\": 8,\n    \"total_tokens\": 8\n  }\n}\nThe embedding object\n\nRepresents an embedding vector returned by embedding endpoint.\n\nindex\ninteger\n\nThe index of the embedding in the list of embeddings.\n\nembedding\narray\n\nThe embedding vector, which is a list of floats. The length of vector depends on the model as listed in the embedding guide.\n\nobject\nstring\n\nThe object type, which is always \"embedding\".\n\nThe embedding object\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n{\n  \"object\": \"embedding\",\n  \"embedding\": [\n    0.0023064255,\n    -0.009327292,\n    .... (1536 floats total for ada-002)\n    -0.0028842222,\n  ],\n  \"index\": 0\n}\nFine-tuning\n\nManage fine-tuning jobs to tailor a model to your specific training data.\n\nRelated guide: Fine-tune models\n\nCreate fine-tuning job\n\nPOST\n \nhttps://api.openai.com/v1/fine_tuning/jobs\n\nCreates a fine-tuning job which begins the process of creating a new model from a given dataset.\n\nResponse includes details of the enqueued job including job status and the name of the fine-tuned models once complete.\n\nLearn more about fine-tuning\n\nRequest body\nmodel\nstring\nRequired\n\nThe name of the model to fine-tune. You can select one of the supported models.\n\ntraining_file\nstring\nRequired\n\nThe ID of an uploaded file that contains training data.\n\nSee upload file for how to upload a file.\n\nYour dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose fine-tune.\n\nSee the fine-tuning guide for more details.\n\nhyperparameters\nobject\nOptional\n\nThe hyperparameters used for the fine-tuning job.\n\nShow properties\nsuffix\nstring or null\nOptional\nDefaults to null\n\nA string of up to 18 characters that will be added to your fine-tuned model name.\n\nFor example, a suffix of \"custom-model-name\" would produce a model name like ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel.\n\nvalidation_file\nstring or null\nOptional\n\nThe ID of an uploaded file that contains validation data.\n\nIf you provide this file, the data is used to generate validation metrics periodically during fine-tuning. These metrics can be viewed in the fine-tuning results file. The same data should not be present in both train and validation files.\n\nYour dataset must be formatted as a JSONL file. You must upload your file with the purpose fine-tune.\n\nSee the fine-tuning guide for more details.\n\nReturns\n\nA fine-tuning.job object.\n\nDefault‍\nEpochs‍\nValidation file‍\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n\ncurl https://api.openai.com/v1/fine_tuning/jobs \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"training_file\": \"file-BK7bzQj3FfZFXr7DbL6xJwfo\",\n    \"model\": \"gpt-3.5-turbo\"\n  }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"created_at\": 1614807352,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"status\": \"queued\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n}\nList fine-tuning jobs\n\nGET\n \nhttps://api.openai.com/v1/fine_tuning/jobs\n\nList your organization's fine-tuning jobs\n\nQuery parameters\nafter\nstring\nOptional\n\nIdentifier for the last job from the previous pagination request.\n\nlimit\ninteger\nOptional\nDefaults to 20\n\nNumber of fine-tuning jobs to retrieve.\n\nReturns\n\nA list of paginated fine-tuning job objects.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n\ncurl https://api.openai.com/v1/fine_tuning/jobs?limit=2 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"fine_tuning.job.event\",\n      \"id\": \"ft-event-TjX0lMfOniCZX64t9PUQT5hn\",\n      \"created_at\": 1689813489,\n      \"level\": \"warn\",\n      \"message\": \"Fine tuning process stopping due to job cancellation\",\n      \"data\": null,\n      \"type\": \"message\"\n    },\n    { ... },\n    { ... }\n  ], \"has_more\": true\n}\nList fine-tuning events\n\nGET\n \nhttps://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/events\n\nGet status updates for a fine-tuning job.\n\nPath parameters\nfine_tuning_job_id\nstring\nRequired\n\nThe ID of the fine-tuning job to get events for.\n\nQuery parameters\nafter\nstring\nOptional\n\nIdentifier for the last event from the previous pagination request.\n\nlimit\ninteger\nOptional\nDefaults to 20\n\nNumber of events to retrieve.\n\nReturns\n\nA list of fine-tuning event objects.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n\ncurl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"fine_tuning.job.event\",\n      \"id\": \"ft-event-ddTJfwuMVpfLXseO0Am0Gqjm\",\n      \"created_at\": 1692407401,\n      \"level\": \"info\",\n      \"message\": \"Fine tuning job successfully completed\",\n      \"data\": null,\n      \"type\": \"message\"\n    },\n    {\n      \"object\": \"fine_tuning.job.event\",\n      \"id\": \"ft-event-tyiGuB72evQncpH87xe505Sv\",\n      \"created_at\": 1692407400,\n      \"level\": \"info\",\n      \"message\": \"New fine-tuned model created: ft:gpt-3.5-turbo:openai::7p4lURel\",\n      \"data\": null,\n      \"type\": \"message\"\n    }\n  ],\n  \"has_more\": true\n}\nRetrieve fine-tuning job\n\nGET\n \nhttps://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}\n\nGet info about a fine-tuning job.\n\nLearn more about fine-tuning\n\nPath parameters\nfine_tuning_job_id\nstring\nRequired\n\nThe ID of the fine-tuning job.\n\nReturns\n\nThe fine-tuning object with the given ID.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n\ncurl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"davinci-002\",\n  \"created_at\": 1692661014,\n  \"finished_at\": 1692661190,\n  \"fine_tuned_model\": \"ft:davinci-002:my-org:custom_suffix:7q8mpxmy\",\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n      \"file-abc123\"\n  ],\n  \"status\": \"succeeded\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n  \"hyperparameters\": {\n      \"n_epochs\": 4,\n  },\n  \"trained_tokens\": 5768\n}\nCancel fine-tuning\n\nPOST\n \nhttps://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancel\n\nImmediately cancel a fine-tune job.\n\nPath parameters\nfine_tuning_job_id\nstring\nRequired\n\nThe ID of the fine-tuning job to cancel.\n\nReturns\n\nThe cancelled fine-tuning object.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n\ncurl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"created_at\": 1689376978,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [],\n  \"hyperparameters\": {\n    \"n_epochs\":  \"auto\"\n  },\n  \"status\": \"cancelled\",\n  \"validation_file\": \"file-abc123\",\n  \"training_file\": \"file-abc123\"\n}\nThe fine-tuning job object\n\nThe fine_tuning.job object represents a fine-tuning job that has been created through the API.\n\nid\nstring\n\nThe object identifier, which can be referenced in the API endpoints.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the fine-tuning job was created.\n\nerror\nobject or null\n\nFor fine-tuning jobs that have failed, this will contain more information on the cause of the failure.\n\nShow properties\nfine_tuned_model\nstring or null\n\nThe name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.\n\nfinished_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.\n\nhyperparameters\nobject\n\nThe hyperparameters used for the fine-tuning job. See the fine-tuning guide for more details.\n\nShow properties\nmodel\nstring\n\nThe base model that is being fine-tuned.\n\nobject\nstring\n\nThe object type, which is always \"fine_tuning.job\".\n\norganization_id\nstring\n\nThe organization that owns the fine-tuning job.\n\nresult_files\narray\n\nThe compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the Files API.\n\nstatus\nstring\n\nThe current status of the fine-tuning job, which can be either validating_files, queued, running, succeeded, failed, or cancelled.\n\ntrained_tokens\ninteger or null\n\nThe total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.\n\ntraining_file\nstring\n\nThe file ID used for training. You can retrieve the training data with the Files API.\n\nvalidation_file\nstring or null\n\nThe file ID used for validation. You can retrieve the validation results with the Files API.\n\nThe fine-tuning job object\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\",\n  \"model\": \"davinci-002\",\n  \"created_at\": 1692661014,\n  \"finished_at\": 1692661190,\n  \"fine_tuned_model\": \"ft:davinci-002:my-org:custom_suffix:7q8mpxmy\",\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n      \"file-abc123\"\n  ],\n  \"status\": \"succeeded\",\n  \"validation_file\": null,\n  \"training_file\": \"file-abc123\",\n  \"hyperparameters\": {\n      \"n_epochs\": 4,\n  },\n  \"trained_tokens\": 5768\n}\nThe fine-tuning job event object\n\nFine-tuning job event object\n\nid\nstring\ncreated_at\ninteger\nlevel\nstring\nmessage\nstring\nobject\nstring\nThe fine-tuning job event object\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n\n{\n  \"object\": \"fine_tuning.job.event\",\n  \"id\": \"ftevent-abc123\"\n  \"created_at\": 1677610602,\n  \"level\": \"info\",\n  \"message\": \"Created fine-tuning job\"\n}\nFiles\n\nFiles are used to upload documents that can be used with features like Assistants and Fine-tuning.\n\nUpload file\n\nPOST\n \nhttps://api.openai.com/v1/files\n\nUpload a file that can be used across various endpoints. The size of all the files uploaded by one organization can be up to 100 GB.\n\nThe size of individual files can be a maximum of 512 MB or 2 million tokens for Assistants. See the Assistants Tools guide to learn more about the types of files supported. The Fine-tuning API only supports .jsonl files.\n\nPlease contact us if you need to increase these storage limits.\n\nRequest body\nfile\nfile\nRequired\n\nThe File object (not file name) to be uploaded.\n\npurpose\nstring\nRequired\n\nThe intended purpose of the uploaded file.\n\nUse \"fine-tune\" for Fine-tuning and \"assistants\" for Assistants and Messages. This allows us to validate the format of the uploaded file is correct for fine-tuning.\n\nReturns\n\nThe uploaded File object.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n\ncurl https://api.openai.com/v1/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F purpose=\"fine-tune\" \\\n  -F file=\"@mydata.jsonl\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"filename\": \"mydata.jsonl\",\n  \"purpose\": \"fine-tune\",\n}\nList files\n\nGET\n \nhttps://api.openai.com/v1/files\n\nReturns a list of files that belong to the user's organization.\n\nQuery parameters\npurpose\nstring\nOptional\n\nOnly return files with the given purpose.\n\nReturns\n\nA list of File objects.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n\ncurl https://api.openai.com/v1/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n{\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 175,\n      \"created_at\": 1613677385,\n      \"filename\": \"salesOverview.pdf\",\n      \"purpose\": \"assistants\",\n    },\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"file\",\n      \"bytes\": 140,\n      \"created_at\": 1613779121,\n      \"filename\": \"puppy.jsonl\",\n      \"purpose\": \"fine-tune\",\n    }\n  ],\n  \"object\": \"list\"\n}\nRetrieve file\n\nGET\n \nhttps://api.openai.com/v1/files/{file_id}\n\nReturns information about a specific file.\n\nPath parameters\nfile_id\nstring\nRequired\n\nThe ID of the file to use for this request.\n\nReturns\n\nThe File object matching the specified ID.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n\ncurl https://api.openai.com/v1/files/file-abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"filename\": \"mydata.jsonl\",\n  \"purpose\": \"fine-tune\",\n}\nDelete file\n\nDELETE\n \nhttps://api.openai.com/v1/files/{file_id}\n\nDelete a file.\n\nPath parameters\nfile_id\nstring\nRequired\n\nThe ID of the file to use for this request.\n\nReturns\n\nDeletion status.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n\ncurl https://api.openai.com/v1/files/file-abc123 \\\n  -X DELETE \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"deleted\": true\n}\nRetrieve file content\n\nGET\n \nhttps://api.openai.com/v1/files/{file_id}/content\n\nReturns the contents of the specified file.\n\nPath parameters\nfile_id\nstring\nRequired\n\nThe ID of the file to use for this request.\n\nReturns\n\nThe file content.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n\ncurl https://api.openai.com/v1/files/file-abc123/content \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" > file.jsonl\nThe file object\n\nThe File object represents a document that has been uploaded to OpenAI.\n\nid\nstring\n\nThe file identifier, which can be referenced in the API endpoints.\n\nbytes\ninteger\n\nThe size of the file, in bytes.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the file was created.\n\nfilename\nstring\n\nThe name of the file.\n\nobject\nstring\n\nThe object type, which is always file.\n\npurpose\nstring\n\nThe intended purpose of the file. Supported values are fine-tune, fine-tune-results, assistants, and assistants_output.\n\nstatus\nDeprecated\nstring\n\nDeprecated. The current status of the file, which can be either uploaded, processed, or error.\n\nstatus_details\nDeprecated\nstring\n\nDeprecated. For details on why a fine-tuning training file failed validation, see the error field on fine_tuning.job.\n\nThe file object\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"filename\": \"salesOverview.pdf\",\n  \"purpose\": \"assistants\",\n}\nImages\n\nGiven a prompt and/or an input image, the model will generate a new image.\n\nRelated guide: Image generation\n\nCreate image\n\nPOST\n \nhttps://api.openai.com/v1/images/generations\n\nCreates an image given a prompt.\n\nRequest body\nprompt\nstring\nRequired\n\nA text description of the desired image(s). The maximum length is 1000 characters for dall-e-2 and 4000 characters for dall-e-3.\n\nmodel\nstring\nOptional\nDefaults to dall-e-2\n\nThe model to use for image generation.\n\nn\ninteger or null\nOptional\nDefaults to 1\n\nThe number of images to generate. Must be between 1 and 10. For dall-e-3, only n=1 is supported.\n\nquality\nstring\nOptional\nDefaults to standard\n\nThe quality of the image that will be generated. hd creates images with finer details and greater consistency across the image. This param is only supported for dall-e-3.\n\nresponse_format\nstring or null\nOptional\nDefaults to url\n\nThe format in which the generated images are returned. Must be one of url or b64_json.\n\nsize\nstring or null\nOptional\nDefaults to 1024x1024\n\nThe size of the generated images. Must be one of 256x256, 512x512, or 1024x1024 for dall-e-2. Must be one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3 models.\n\nstyle\nstring or null\nOptional\nDefaults to vivid\n\nThe style of the generated images. Must be one of vivid or natural. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for dall-e-3.\n\nuser\nstring\nOptional\n\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.\n\nReturns\n\nReturns a list of image objects.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\ncurl https://api.openai.com/v1/images/generations \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"dall-e-3\",\n    \"prompt\": \"A cute baby sea otter\",\n    \"n\": 1,\n    \"size\": \"1024x1024\"\n  }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n    }\n  ]\n}\nCreate image edit\n\nPOST\n \nhttps://api.openai.com/v1/images/edits\n\nCreates an edited or extended image given an original image and a prompt.\n\nRequest body\nimage\nfile\nRequired\n\nThe image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.\n\nprompt\nstring\nRequired\n\nA text description of the desired image(s). The maximum length is 1000 characters.\n\nmask\nfile\nOptional\n\nAn additional image whose fully transparent areas (e.g. where alpha is zero) indicate where image should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as image.\n\nmodel\nstring\nOptional\nDefaults to dall-e-2\n\nThe model to use for image generation. Only dall-e-2 is supported at this time.\n\nn\ninteger or null\nOptional\nDefaults to 1\n\nThe number of images to generate. Must be between 1 and 10.\n\nsize\nstring or null\nOptional\nDefaults to 1024x1024\n\nThe size of the generated images. Must be one of 256x256, 512x512, or 1024x1024.\n\nresponse_format\nstring or null\nOptional\nDefaults to url\n\nThe format in which the generated images are returned. Must be one of url or b64_json.\n\nuser\nstring\nOptional\n\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.\n\nReturns\n\nReturns a list of image objects.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n\ncurl https://api.openai.com/v1/images/edits \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F image=\"@otter.png\" \\\n  -F mask=\"@mask.png\" \\\n  -F prompt=\"A cute baby sea otter wearing a beret\" \\\n  -F n=2 \\\n  -F size=\"1024x1024\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n    }\n  ]\n}\nCreate image variation\n\nPOST\n \nhttps://api.openai.com/v1/images/variations\n\nCreates a variation of a given image.\n\nRequest body\nimage\nfile\nRequired\n\nThe image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.\n\nmodel\nstring\nOptional\nDefaults to dall-e-2\n\nThe model to use for image generation. Only dall-e-2 is supported at this time.\n\nn\ninteger or null\nOptional\nDefaults to 1\n\nThe number of images to generate. Must be between 1 and 10. For dall-e-3, only n=1 is supported.\n\nresponse_format\nstring or null\nOptional\nDefaults to url\n\nThe format in which the generated images are returned. Must be one of url or b64_json.\n\nsize\nstring or null\nOptional\nDefaults to 1024x1024\n\nThe size of the generated images. Must be one of 256x256, 512x512, or 1024x1024.\n\nuser\nstring\nOptional\n\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.\n\nReturns\n\nReturns a list of image objects.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n\ncurl https://api.openai.com/v1/images/variations \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -F image=\"@otter.png\" \\\n  -F n=2 \\\n  -F size=\"1024x1024\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n    }\n  ]\n}\nThe image object\n\nRepresents the url or the content of an image generated by the OpenAI API.\n\nb64_json\nstring\n\nThe base64-encoded JSON of the generated image, if response_format is b64_json.\n\nurl\nstring\n\nThe URL of the generated image, if response_format is url (default).\n\nrevised_prompt\nstring\n\nThe prompt that was used to generate the image, if there was any revision to the prompt.\n\nThe image object\nCopy‍\n1\n2\n3\n4\n\n{\n  \"url\": \"...\",\n  \"revised_prompt\": \"...\"\n}\nModels\n\nList and describe the various models available in the API. You can refer to the Models documentation to understand what models are available and the differences between them.\n\nList models\n\nGET\n \nhttps://api.openai.com/v1/models\n\nLists the currently available models, and provides basic information about each one such as the owner and availability.\n\nReturns\n\nA list of model objects.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n\ncurl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"model-id-0\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"organization-owner\"\n    },\n    {\n      \"id\": \"model-id-1\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"organization-owner\",\n    },\n    {\n      \"id\": \"model-id-2\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n      \"owned_by\": \"openai\"\n    },\n  ],\n  \"object\": \"list\"\n}\nRetrieve model\n\nGET\n \nhttps://api.openai.com/v1/models/{model}\n\nRetrieves a model instance, providing basic information about the model such as the owner and permissioning.\n\nPath parameters\nmodel\nstring\nRequired\n\nThe ID of the model to use for this request\n\nReturns\n\nThe model object matching the specified ID.\n\nExample request\ngpt-3.5-turbo-instruct\ngpt-3.5-turbo-instruct\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n\ncurl https://api.openai.com/v1/models/gpt-3.5-turbo-instruct \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\ngpt-3.5-turbo-instruct\ngpt-3.5-turbo-instruct\nCopy‍\n1\n2\n3\n4\n5\n6\n\n{\n  \"id\": \"gpt-3.5-turbo-instruct\",\n  \"object\": \"model\",\n  \"created\": 1686935002,\n  \"owned_by\": \"openai\"\n}\nDelete a fine-tuned model\n\nDELETE\n \nhttps://api.openai.com/v1/models/{model}\n\nDelete a fine-tuned model. You must have the Owner role in your organization to delete a model.\n\nPath parameters\nmodel\nstring\nRequired\n\nThe model to delete\n\nReturns\n\nDeletion status.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n\ncurl https://api.openai.com/v1/models/ft:gpt-3.5-turbo:acemeco:suffix:abc123 \\\n  -X DELETE \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n\n{\n  \"id\": \"ft:gpt-3.5-turbo:acemeco:suffix:abc123\",\n  \"object\": \"model\",\n  \"deleted\": true\n}\nThe model object\n\nDescribes an OpenAI model offering that can be used with the API.\n\nid\nstring\n\nThe model identifier, which can be referenced in the API endpoints.\n\ncreated\ninteger\n\nThe Unix timestamp (in seconds) when the model was created.\n\nobject\nstring\n\nThe object type, which is always \"model\".\n\nowned_by\nstring\n\nThe organization that owns the model.\n\nThe model object\ngpt-3.5-turbo-instruct\nCopy‍\n1\n2\n3\n4\n5\n6\n\n{\n  \"id\": \"davinci\",\n  \"object\": \"model\",\n  \"created\": 1686935002,\n  \"owned_by\": \"openai\"\n}\nModerations\n\nGiven a input text, outputs if the model classifies it as violating OpenAI's content policy.\n\nRelated guide: Moderations\n\nCreate moderation\n\nPOST\n \nhttps://api.openai.com/v1/moderations\n\nClassifies if text violates OpenAI's Content Policy\n\nRequest body\ninput\nstring or array\nRequired\n\nThe input text to classify\n\nmodel\nstring\nOptional\nDefaults to text-moderation-latest\n\nTwo content moderations models are available: text-moderation-stable and text-moderation-latest.\n\nThe default is text-moderation-latest which will be automatically upgraded over time. This ensures you are always using our most accurate model. If you use text-moderation-stable, we will provide advanced notice before updating the model. Accuracy of text-moderation-stable may be slightly lower than for text-moderation-latest.\n\nReturns\n\nA moderation object.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n\ncurl https://api.openai.com/v1/moderations \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"input\": \"I want to kill them.\"\n  }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n{\n  \"id\": \"modr-XXXXX\",\n  \"model\": \"text-moderation-005\",\n  \"results\": [\n    {\n      \"flagged\": true,\n      \"categories\": {\n        \"sexual\": false,\n        \"hate\": false,\n        \"harassment\": false,\n        \"self-harm\": false,\n        \"sexual/minors\": false,\n        \"hate/threatening\": false,\n        \"violence/graphic\": false,\n        \"self-harm/intent\": false,\n        \"self-harm/instructions\": false,\n        \"harassment/threatening\": true,\n        \"violence\": true,\n      },\n      \"category_scores\": {\n        \"sexual\": 1.2282071e-06,\n        \"hate\": 0.010696256,\n        \"harassment\": 0.29842457,\n        \"self-harm\": 1.5236925e-08,\n        \"sexual/minors\": 5.7246268e-08,\n        \"hate/threatening\": 0.0060676364,\n        \"violence/graphic\": 4.435014e-06,\n        \"self-harm/intent\": 8.098441e-10,\n        \"self-harm/instructions\": 2.8498655e-11,\n        \"harassment/threatening\": 0.63055265,\n        \"violence\": 0.99011886,\n      }\n    }\n  ]\n}\nThe moderation object\n\nRepresents policy compliance report by OpenAI's content moderation model against a given input.\n\nid\nstring\n\nThe unique identifier for the moderation request.\n\nmodel\nstring\n\nThe model used to generate the moderation results.\n\nresults\narray\n\nA list of moderation objects.\n\nShow properties\nThe moderation object\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n{\n  \"id\": \"modr-XXXXX\",\n  \"model\": \"text-moderation-005\",\n  \"results\": [\n    {\n      \"flagged\": true,\n      \"categories\": {\n        \"sexual\": false,\n        \"hate\": false,\n        \"harassment\": false,\n        \"self-harm\": false,\n        \"sexual/minors\": false,\n        \"hate/threatening\": false,\n        \"violence/graphic\": false,\n        \"self-harm/intent\": false,\n        \"self-harm/instructions\": false,\n        \"harassment/threatening\": true,\n        \"violence\": true,\n      },\n      \"category_scores\": {\n        \"sexual\": 1.2282071e-06,\n        \"hate\": 0.010696256,\n        \"harassment\": 0.29842457,\n        \"self-harm\": 1.5236925e-08,\n        \"sexual/minors\": 5.7246268e-08,\n        \"hate/threatening\": 0.0060676364,\n        \"violence/graphic\": 4.435014e-06,\n        \"self-harm/intent\": 8.098441e-10,\n        \"self-harm/instructions\": 2.8498655e-11,\n        \"harassment/threatening\": 0.63055265,\n        \"violence\": 0.99011886,\n      }\n    }\n  ]\n}\nAssistantsBeta\n\nBuild assistants that can call models and use tools to perform tasks.\n\nGet started with the Assistants API\n\nCreate assistantBeta\n\nPOST\n \nhttps://api.openai.com/v1/assistants\n\nCreate an assistant with a model and instructions.\n\nRequest body\nmodel\nRequired\n\nID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.\n\nname\nstring or null\nOptional\n\nThe name of the assistant. The maximum length is 256 characters.\n\ndescription\nstring or null\nOptional\n\nThe description of the assistant. The maximum length is 512 characters.\n\ninstructions\nstring or null\nOptional\n\nThe system instructions that the assistant uses. The maximum length is 32768 characters.\n\ntools\narray\nOptional\nDefaults to []\n\nA list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types code_interpreter, retrieval, or function.\n\nShow possible types\nfile_ids\narray\nOptional\nDefaults to []\n\nA list of file IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.\n\nmetadata\nmap\nOptional\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n\nReturns\n\nAn assistant object.\n\nCode Interpreter‍\nFiles‍\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\ncurl \"https://api.openai.com/v1/assistants\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\" \\\n  -d '{\n    \"instructions\": \"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n    \"name\": \"Math Tutor\",\n    \"tools\": [{\"type\": \"code_interpreter\"}],\n    \"model\": \"gpt-4\"\n  }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1698984975,\n  \"name\": \"Math Tutor\",\n  \"description\": null,\n  \"model\": \"gpt-4\",\n  \"instructions\": \"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"file_ids\": [],\n  \"metadata\": {}\n}\nCreate assistant fileBeta\n\nPOST\n \nhttps://api.openai.com/v1/assistants/{assistant_id}/files\n\nCreate an assistant file by attaching a File to an assistant.\n\nPath parameters\nassistant_id\nstring\nRequired\n\nThe ID of the assistant for which to create a File.\n\nRequest body\nfile_id\nstring\nRequired\n\nA File ID (with purpose=\"assistants\") that the assistant should use. Useful for tools like retrieval and code_interpreter that can access files.\n\nReturns\n\nAn assistant file object.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n\ncurl https://api.openai.com/v1/assistants/asst_abc123/files \\\n    -H 'Authorization: Bearer $OPENAI_API_KEY\"' \\\n    -H 'Content-Type: application/json' \\\n    -H 'OpenAI-Beta: assistants=v1' \\\n    -d '{\n      \"file_id\": \"file-abc123\"\n    }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"assistant.file\",\n  \"created_at\": 1699055364,\n  \"assistant_id\": \"asst_abc123\"\n}\nList assistantsBeta\n\nGET\n \nhttps://api.openai.com/v1/assistants\n\nReturns a list of assistants.\n\nQuery parameters\nlimit\ninteger\nOptional\nDefaults to 20\n\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\nOptional\nDefaults to desc\n\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nafter\nstring\nOptional\n\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\nOptional\n\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\nReturns\n\nA list of assistant objects.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n\ncurl \"https://api.openai.com/v1/assistants?order=desc&limit=20\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"asst_abc123\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982736,\n      \"name\": \"Coding Tutor\",\n      \"description\": null,\n      \"model\": \"gpt-4\",\n      \"instructions\": \"You are a helpful assistant designed to make me better at coding!\",\n      \"tools\": [],\n      \"file_ids\": [],\n      \"metadata\": {}\n    },\n    {\n      \"id\": \"asst_abc456\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982718,\n      \"name\": \"My Assistant\",\n      \"description\": null,\n      \"model\": \"gpt-4\",\n      \"instructions\": \"You are a helpful assistant designed to make me better at coding!\",\n      \"tools\": [],\n      \"file_ids\": [],\n      \"metadata\": {}\n    },\n    {\n      \"id\": \"asst_abc789\",\n      \"object\": \"assistant\",\n      \"created_at\": 1698982643,\n      \"name\": null,\n      \"description\": null,\n      \"model\": \"gpt-4\",\n      \"instructions\": null,\n      \"tools\": [],\n      \"file_ids\": [],\n      \"metadata\": {}\n    }\n  ],\n  \"first_id\": \"asst_abc123\",\n  \"last_id\": \"asst_abc789\",\n  \"has_more\": false\n}\nList assistant filesBeta\n\nGET\n \nhttps://api.openai.com/v1/assistants/{assistant_id}/files\n\nReturns a list of assistant files.\n\nPath parameters\nassistant_id\nstring\nRequired\n\nThe ID of the assistant the file belongs to.\n\nQuery parameters\nlimit\ninteger\nOptional\nDefaults to 20\n\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\nOptional\nDefaults to desc\n\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nafter\nstring\nOptional\n\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\nOptional\n\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\nReturns\n\nA list of assistant file objects.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n\ncurl https://api.openai.com/v1/assistants/asst_abc123/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v1\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"assistant.file\",\n      \"created_at\": 1699060412,\n      \"assistant_id\": \"asst_abc123\"\n    },\n    {\n      \"id\": \"file-abc456\",\n      \"object\": \"assistant.file\",\n      \"created_at\": 1699060412,\n      \"assistant_id\": \"asst_abc123\"\n    }\n  ],\n  \"first_id\": \"file-abc123\",\n  \"last_id\": \"file-abc456\",\n  \"has_more\": false\n}\nRetrieve assistantBeta\n\nGET\n \nhttps://api.openai.com/v1/assistants/{assistant_id}\n\nRetrieves an assistant.\n\nPath parameters\nassistant_id\nstring\nRequired\n\nThe ID of the assistant to retrieve.\n\nReturns\n\nThe assistant object matching the specified ID.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n\ncurl https://api.openai.com/v1/assistants/asst_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1699009709,\n  \"name\": \"HR Helper\",\n  \"description\": null,\n  \"model\": \"gpt-4\",\n  \"instructions\": \"You are an HR bot, and you have access to files to answer employee questions about company policies.\",\n  \"tools\": [\n    {\n      \"type\": \"retrieval\"\n    }\n  ],\n  \"file_ids\": [\n    \"file-abc123\"\n  ],\n  \"metadata\": {}\n}\nRetrieve assistant fileBeta\n\nGET\n \nhttps://api.openai.com/v1/assistants/{assistant_id}/files/{file_id}\n\nRetrieves an AssistantFile.\n\nPath parameters\nassistant_id\nstring\nRequired\n\nThe ID of the assistant who the file belongs to.\n\nfile_id\nstring\nRequired\n\nThe ID of the file we're getting.\n\nReturns\n\nThe assistant file object matching the specified ID.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n\ncurl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \\\n  -H 'Authorization: Bearer $OPENAI_API_KEY\"' \\\n  -H 'Content-Type: application/json' \\\n  -H 'OpenAI-Beta: assistants=v1'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"assistant.file\",\n  \"created_at\": 1699055364,\n  \"assistant_id\": \"asst_abc123\"\n}\nModify assistantBeta\n\nPOST\n \nhttps://api.openai.com/v1/assistants/{assistant_id}\n\nModifies an assistant.\n\nPath parameters\nassistant_id\nstring\nRequired\n\nThe ID of the assistant to modify.\n\nRequest body\nmodel\nOptional\n\nID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.\n\nname\nstring or null\nOptional\n\nThe name of the assistant. The maximum length is 256 characters.\n\ndescription\nstring or null\nOptional\n\nThe description of the assistant. The maximum length is 512 characters.\n\ninstructions\nstring or null\nOptional\n\nThe system instructions that the assistant uses. The maximum length is 32768 characters.\n\ntools\narray\nOptional\nDefaults to []\n\nA list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types code_interpreter, retrieval, or function.\n\nShow possible types\nfile_ids\narray\nOptional\nDefaults to []\n\nA list of File IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order. If a file was previously attached to the list but does not show up in the list, it will be deleted from the assistant.\n\nmetadata\nmap\nOptional\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n\nReturns\n\nThe modified assistant object.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\ncurl https://api.openai.com/v1/assistants/asst_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\" \\\n  -d '{\n      \"instructions\": \"You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.\",\n      \"tools\": [{\"type\": \"retrieval\"}],\n      \"model\": \"gpt-4\",\n      \"file_ids\": [\"file-abc123\", \"file-abc456\"]\n    }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1699009709,\n  \"name\": \"HR Helper\",\n  \"description\": null,\n  \"model\": \"gpt-4\",\n  \"instructions\": \"You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.\",\n  \"tools\": [\n    {\n      \"type\": \"retrieval\"\n    }\n  ],\n  \"file_ids\": [\n    \"file-abc123\",\n    \"file-abc456\"\n  ],\n  \"metadata\": {}\n}\nDelete assistantBeta\n\nDELETE\n \nhttps://api.openai.com/v1/assistants/{assistant_id}\n\nDelete an assistant.\n\nPath parameters\nassistant_id\nstring\nRequired\n\nThe ID of the assistant to delete.\n\nReturns\n\nDeletion status\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n\ncurl https://api.openai.com/v1/assistants/asst_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\" \\\n  -X DELETE\nResponse\nCopy‍\n1\n2\n3\n4\n5\n\n{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant.deleted\",\n  \"deleted\": true\n}\nDelete assistant fileBeta\n\nDELETE\n \nhttps://api.openai.com/v1/assistants/{assistant_id}/files/{file_id}\n\nDelete an assistant file.\n\nPath parameters\nassistant_id\nstring\nRequired\n\nThe ID of the assistant that the file belongs to.\n\nfile_id\nstring\nRequired\n\nThe ID of the file to delete.\n\nReturns\n\nDeletion status\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n\ncurl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v1\" \\\n  -X DELETE\nResponse\nCopy‍\n1\n2\n3\n4\n5\n\n{\n  id: \"file-abc123\",\n  object: \"assistant.file.deleted\",\n  deleted: true\n}\nThe assistant objectBeta\n\nRepresents an assistant that can call the model and use tools.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints.\n\nobject\nstring\n\nThe object type, which is always assistant.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the assistant was created.\n\nname\nstring or null\n\nThe name of the assistant. The maximum length is 256 characters.\n\ndescription\nstring or null\n\nThe description of the assistant. The maximum length is 512 characters.\n\nmodel\nstring\n\nID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.\n\ninstructions\nstring or null\n\nThe system instructions that the assistant uses. The maximum length is 32768 characters.\n\ntools\narray\n\nA list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types code_interpreter, retrieval, or function.\n\nShow possible types\nfile_ids\narray\n\nA list of file IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.\n\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n\nThe assistant object\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"created_at\": 1698984975,\n  \"name\": \"Math Tutor\",\n  \"description\": null,\n  \"model\": \"gpt-4\",\n  \"instructions\": \"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"file_ids\": [],\n  \"metadata\": {}\n}\nThe assistant file objectBeta\n\nA list of Files attached to an assistant.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints.\n\nobject\nstring\n\nThe object type, which is always assistant.file.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the assistant file was created.\n\nassistant_id\nstring\n\nThe assistant ID that the file is attached to.\n\nThe assistant file object\nCopy‍\n1\n2\n3\n4\n5\n6\n\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"assistant.file\",\n  \"created_at\": 1699055364,\n  \"assistant_id\": \"asst_abc123\"\n}\nThreadsBeta\n\nCreate threads that assistants can interact with.\n\nRelated guide: Assistants\n\nCreate threadBeta\n\nPOST\n \nhttps://api.openai.com/v1/threads\n\nCreate a thread.\n\nRequest body\nmessages\narray\nOptional\n\nA list of messages to start the thread with.\n\nShow properties\nmetadata\nmap\nOptional\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n\nReturns\n\nA thread object.\n\nEmpty‍\nMessages‍\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n\ncurl https://api.openai.com/v1/threads \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\" \\\n  -d ''\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n\n{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1699012949,\n  \"metadata\": {}\n}\nRetrieve threadBeta\n\nGET\n \nhttps://api.openai.com/v1/threads/{thread_id}\n\nRetrieves a thread.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread to retrieve.\n\nReturns\n\nThe thread object matching the specified ID.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n\ncurl https://api.openai.com/v1/threads/thread_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n\n{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1699014083,\n  \"metadata\": {}\n}\nModify threadBeta\n\nPOST\n \nhttps://api.openai.com/v1/threads/{thread_id}\n\nModifies a thread.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread to modify. Only the metadata can be modified.\n\nRequest body\nmetadata\nmap\nOptional\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n\nReturns\n\nThe modified thread object matching the specified ID.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\ncurl https://api.openai.com/v1/threads/thread_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\" \\\n  -d '{\n      \"metadata\": {\n        \"modified\": \"true\",\n        \"user\": \"abc123\"\n      }\n    }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1699014083,\n  \"metadata\": {\n    \"modified\": \"true\",\n    \"user\": \"abc123\"\n  }\n}\nDelete threadBeta\n\nDELETE\n \nhttps://api.openai.com/v1/threads/{thread_id}\n\nDelete a thread.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread to delete.\n\nReturns\n\nDeletion status\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n\ncurl https://api.openai.com/v1/threads/thread_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\" \\\n  -X DELETE\nResponse\nCopy‍\n1\n2\n3\n4\n5\n\n{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread.deleted\",\n  \"deleted\": true\n}\nThe thread objectBeta\n\nRepresents a thread that contains messages.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints.\n\nobject\nstring\n\nThe object type, which is always thread.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the thread was created.\n\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n\nThe thread object\nCopy‍\n1\n2\n3\n4\n5\n6\n\n{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"created_at\": 1698107661,\n  \"metadata\": {}\n}\nMessagesBeta\n\nCreate messages within threads\n\nRelated guide: Assistants\n\nCreate messageBeta\n\nPOST\n \nhttps://api.openai.com/v1/threads/{thread_id}/messages\n\nCreate a message.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread to create a message for.\n\nRequest body\nrole\nstring\nRequired\n\nThe role of the entity that is creating the message. Currently only user is supported.\n\ncontent\nstring\nRequired\n\nThe content of the message.\n\nfile_ids\narray\nOptional\nDefaults to []\n\nA list of File IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like retrieval and code_interpreter that can access and use files.\n\nmetadata\nmap\nOptional\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n\nReturns\n\nA message object.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n\ncurl https://api.openai.com/v1/threads/thread_abc123/messages \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\" \\\n  -d '{\n      \"role\": \"user\",\n      \"content\": \"How does AI work? Explain it in simple terms.\"\n    }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1699017614,\n  \"thread_id\": \"thread_abc123\",\n  \"role\": \"user\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"How does AI work? Explain it in simple terms.\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"file_ids\": [],\n  \"assistant_id\": null,\n  \"run_id\": null,\n  \"metadata\": {}\n}\nList messagesBeta\n\nGET\n \nhttps://api.openai.com/v1/threads/{thread_id}/messages\n\nReturns a list of messages for a given thread.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread the messages belong to.\n\nQuery parameters\nlimit\ninteger\nOptional\nDefaults to 20\n\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\nOptional\nDefaults to desc\n\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nafter\nstring\nOptional\n\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\nOptional\n\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\nReturns\n\nA list of message objects.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n\ncurl https://api.openai.com/v1/threads/thread_abc123/messages \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"msg_abc123\",\n      \"object\": \"thread.message\",\n      \"created_at\": 1699016383,\n      \"thread_id\": \"thread_abc123\",\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": {\n            \"value\": \"How does AI work? Explain it in simple terms.\",\n            \"annotations\": []\n          }\n        }\n      ],\n      \"file_ids\": [],\n      \"assistant_id\": null,\n      \"run_id\": null,\n      \"metadata\": {}\n    },\n    {\n      \"id\": \"msg_abc456\",\n      \"object\": \"thread.message\",\n      \"created_at\": 1699016383,\n      \"thread_id\": \"thread_abc123\",\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": {\n            \"value\": \"Hello, what is AI?\",\n            \"annotations\": []\n          }\n        }\n      ],\n      \"file_ids\": [\n        \"file-abc123\"\n      ],\n      \"assistant_id\": null,\n      \"run_id\": null,\n      \"metadata\": {}\n    }\n  ],\n  \"first_id\": \"msg_abc123\",\n  \"last_id\": \"msg_abc456\",\n  \"has_more\": false\n}\nList message filesBeta\n\nGET\n \nhttps://api.openai.com/v1/threads/{thread_id}/messages/{message_id}/files\n\nReturns a list of message files.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread that the message and files belong to.\n\nmessage_id\nstring\nRequired\n\nThe ID of the message that the files belongs to.\n\nQuery parameters\nlimit\ninteger\nOptional\nDefaults to 20\n\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\nOptional\nDefaults to desc\n\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nafter\nstring\nOptional\n\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\nOptional\n\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\nReturns\n\nA list of message file objects.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n\ncurl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v1\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"thread.message.file\",\n      \"created_at\": 1699061776,\n      \"message_id\": \"msg_abc123\"\n    },\n    {\n      \"id\": \"file-abc123\",\n      \"object\": \"thread.message.file\",\n      \"created_at\": 1699061776,\n      \"message_id\": \"msg_abc123\"\n    }\n  ],\n  \"first_id\": \"file-abc123\",\n  \"last_id\": \"file-abc123\",\n  \"has_more\": false\n}\nRetrieve messageBeta\n\nGET\n \nhttps://api.openai.com/v1/threads/{thread_id}/messages/{message_id}\n\nRetrieve a message.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread to which this message belongs.\n\nmessage_id\nstring\nRequired\n\nThe ID of the message to retrieve.\n\nReturns\n\nThe message object matching the specified ID.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n\ncurl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1699017614,\n  \"thread_id\": \"thread_abc123\",\n  \"role\": \"user\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"How does AI work? Explain it in simple terms.\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"file_ids\": [],\n  \"assistant_id\": null,\n  \"run_id\": null,\n  \"metadata\": {}\n}\nRetrieve message fileBeta\n\nGET\n \nhttps://api.openai.com/v1/threads/{thread_id}/messages/{message_id}/files/{file_id}\n\nRetrieves a message file.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread to which the message and File belong.\n\nmessage_id\nstring\nRequired\n\nThe ID of the message the file belongs to.\n\nfile_id\nstring\nRequired\n\nThe ID of the file being retrieved.\n\nReturns\n\nThe message file object.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n\ncurl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files/file-abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v1\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"thread.message.file\",\n  \"created_at\": 1699061776,\n  \"message_id\": \"msg_abc123\"\n}\nModify messageBeta\n\nPOST\n \nhttps://api.openai.com/v1/threads/{thread_id}/messages/{message_id}\n\nModifies a message.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread to which this message belongs.\n\nmessage_id\nstring\nRequired\n\nThe ID of the message to modify.\n\nRequest body\nmetadata\nmap\nOptional\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n\nReturns\n\nThe modified message object.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\ncurl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\" \\\n  -d '{\n      \"metadata\": {\n        \"modified\": \"true\",\n        \"user\": \"abc123\"\n      }\n    }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1699017614,\n  \"thread_id\": \"thread_abc123\",\n  \"role\": \"user\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"How does AI work? Explain it in simple terms.\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"file_ids\": [],\n  \"assistant_id\": null,\n  \"run_id\": null,\n  \"metadata\": {\n    \"modified\": \"true\",\n    \"user\": \"abc123\"\n  }\n}\nThe message objectBeta\n\nRepresents a message within a thread.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints.\n\nobject\nstring\n\nThe object type, which is always thread.message.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the message was created.\n\nthread_id\nstring\n\nThe thread ID that this message belongs to.\n\nrole\nstring\n\nThe entity that produced the message. One of user or assistant.\n\ncontent\narray\n\nThe content of the message in array of text and/or images.\n\nShow possible types\nassistant_id\nstring or null\n\nIf applicable, the ID of the assistant that authored this message.\n\nrun_id\nstring or null\n\nIf applicable, the ID of the run associated with the authoring of this message.\n\nfile_ids\narray\n\nA list of file IDs that the assistant should use. Useful for tools like retrieval and code_interpreter that can access files. A maximum of 10 files can be attached to a message.\n\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n\nThe message object\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n  \"created_at\": 1698983503,\n  \"thread_id\": \"thread_abc123\",\n  \"role\": \"assistant\",\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n        \"value\": \"Hi! How can I help you today?\",\n        \"annotations\": []\n      }\n    }\n  ],\n  \"file_ids\": [],\n  \"assistant_id\": \"asst_abc123\",\n  \"run_id\": \"run_abc123\",\n  \"metadata\": {}\n}\nThe message file objectBeta\n\nA list of files attached to a message.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints.\n\nobject\nstring\n\nThe object type, which is always thread.message.file.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the message file was created.\n\nmessage_id\nstring\n\nThe ID of the message that the File is attached to.\n\nThe message file object\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n\n{\n  \"id\": \"file-abc123\",\n  \"object\": \"thread.message.file\",\n  \"created_at\": 1698107661,\n  \"message_id\": \"message_QLoItBbqwyAJEzlTy4y9kOMM\",\n  \"file_id\": \"file-abc123\"\n}\nRunsBeta\n\nRepresents an execution run on a thread.\n\nRelated guide: Assistants\n\nCreate runBeta\n\nPOST\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs\n\nCreate a run.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread to run.\n\nRequest body\nassistant_id\nstring\nRequired\n\nThe ID of the assistant to use to execute this run.\n\nmodel\nstring or null\nOptional\n\nThe ID of the Model to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.\n\ninstructions\nstring or null\nOptional\n\nOverrides the instructions of the assistant. This is useful for modifying the behavior on a per-run basis.\n\nadditional_instructions\nstring or null\nOptional\n\nAppends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.\n\ntools\narray or null\nOptional\n\nOverride the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.\n\nShow possible types\nmetadata\nmap\nOptional\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n\nReturns\n\nA run object.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n\ncurl https://api.openai.com/v1/threads/thread_abc123/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v1\" \\\n  -d '{\n    \"assistant_id\": \"asst_abc123\"\n  }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699063290,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"queued\",\n  \"started_at\": 1699063290,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699063291,\n  \"last_error\": null,\n  \"model\": \"gpt-4\",\n  \"instructions\": null,\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"file_ids\": [\n    \"file-abc123\",\n    \"file-abc456\"\n  ],\n  \"metadata\": {},\n  \"usage\": null\n}\nCreate thread and runBeta\n\nPOST\n \nhttps://api.openai.com/v1/threads/runs\n\nCreate a thread and run it in one request.\n\nRequest body\nassistant_id\nstring\nRequired\n\nThe ID of the assistant to use to execute this run.\n\nthread\nobject\nOptional\nShow properties\nmodel\nstring or null\nOptional\n\nThe ID of the Model to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.\n\ninstructions\nstring or null\nOptional\n\nOverride the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.\n\ntools\narray or null\nOptional\n\nOverride the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.\n\nmetadata\nmap\nOptional\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n\nReturns\n\nA run object.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\ncurl https://api.openai.com/v1/threads/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v1\" \\\n  -d '{\n      \"assistant_id\": \"asst_abc123\",\n      \"thread\": {\n        \"messages\": [\n          {\"role\": \"user\", \"content\": \"Explain deep learning to a 5 year old.\"}\n        ]\n      }\n    }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699076792,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"queued\",\n  \"started_at\": null,\n  \"expires_at\": 1699077392,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"last_error\": null,\n  \"model\": \"gpt-4\",\n  \"instructions\": \"You are a helpful assistant.\",\n  \"tools\": [],\n  \"file_ids\": [],\n  \"metadata\": {},\n  \"usage\": null\n}\nList runsBeta\n\nGET\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs\n\nReturns a list of runs belonging to a thread.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread the run belongs to.\n\nQuery parameters\nlimit\ninteger\nOptional\nDefaults to 20\n\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\nOptional\nDefaults to desc\n\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nafter\nstring\nOptional\n\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\nOptional\n\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\nReturns\n\nA list of run objects.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n\ncurl https://api.openai.com/v1/threads/thread_abc123/runs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v1\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"run_abc123\",\n      \"object\": \"thread.run\",\n      \"created_at\": 1699075072,\n      \"assistant_id\": \"asst_abc123\",\n      \"thread_id\": \"thread_abc123\",\n      \"status\": \"completed\",\n      \"started_at\": 1699075072,\n      \"expires_at\": null,\n      \"cancelled_at\": null,\n      \"failed_at\": null,\n      \"completed_at\": 1699075073,\n      \"last_error\": null,\n      \"model\": \"gpt-3.5-turbo\",\n      \"instructions\": null,\n      \"tools\": [\n        {\n          \"type\": \"code_interpreter\"\n        }\n      ],\n      \"file_ids\": [\n        \"file-abc123\",\n        \"file-abc456\"\n      ],\n      \"metadata\": {},\n      \"usage\": {\n        \"prompt_tokens\": 123,\n        \"completion_tokens\": 456,\n        \"total_tokens\": 579\n      }\n    },\n    {\n      \"id\": \"run_abc456\",\n      \"object\": \"thread.run\",\n      \"created_at\": 1699063290,\n      \"assistant_id\": \"asst_abc123\",\n      \"thread_id\": \"thread_abc123\",\n      \"status\": \"completed\",\n      \"started_at\": 1699063290,\n      \"expires_at\": null,\n      \"cancelled_at\": null,\n      \"failed_at\": null,\n      \"completed_at\": 1699063291,\n      \"last_error\": null,\n      \"model\": \"gpt-3.5-turbo\",\n      \"instructions\": null,\n      \"tools\": [\n        {\n          \"type\": \"code_interpreter\"\n        }\n      ],\n      \"file_ids\": [\n        \"file-abc123\",\n        \"file-abc456\"\n      ],\n      \"metadata\": {},\n      \"usage\": {\n        \"prompt_tokens\": 123,\n        \"completion_tokens\": 456,\n        \"total_tokens\": 579\n      }\n    }\n  ],\n  \"first_id\": \"run_abc123\",\n  \"last_id\": \"run_abc456\",\n  \"has_more\": false\n}\nList run stepsBeta\n\nGET\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/steps\n\nReturns a list of run steps belonging to a run.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread the run and run steps belong to.\n\nrun_id\nstring\nRequired\n\nThe ID of the run the run steps belong to.\n\nQuery parameters\nlimit\ninteger\nOptional\nDefaults to 20\n\nA limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n\norder\nstring\nOptional\nDefaults to desc\n\nSort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.\n\nafter\nstring\nOptional\n\nA cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n\nbefore\nstring\nOptional\n\nA cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n\nReturns\n\nA list of run step objects.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n\ncurl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v1\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"step_abc123\",\n      \"object\": \"thread.run.step\",\n      \"created_at\": 1699063291,\n      \"run_id\": \"run_abc123\",\n      \"assistant_id\": \"asst_abc123\",\n      \"thread_id\": \"thread_abc123\",\n      \"type\": \"message_creation\",\n      \"status\": \"completed\",\n      \"cancelled_at\": null,\n      \"completed_at\": 1699063291,\n      \"expired_at\": null,\n      \"failed_at\": null,\n      \"last_error\": null,\n      \"step_details\": {\n        \"type\": \"message_creation\",\n        \"message_creation\": {\n          \"message_id\": \"msg_abc123\"\n        }\n      },\n      \"usage\": {\n        \"prompt_tokens\": 123,\n        \"completion_tokens\": 456,\n        \"total_tokens\": 579\n      }\n    }\n  ],\n  \"first_id\": \"step_abc123\",\n  \"last_id\": \"step_abc456\",\n  \"has_more\": false\n}\nRetrieve runBeta\n\nGET\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs/{run_id}\n\nRetrieves a run.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread that was run.\n\nrun_id\nstring\nRequired\n\nThe ID of the run to retrieve.\n\nReturns\n\nThe run object matching the specified ID.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n\ncurl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699075072,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n  \"started_at\": 1699075072,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699075073,\n  \"last_error\": null,\n  \"model\": \"gpt-3.5-turbo\",\n  \"instructions\": null,\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"file_ids\": [\n    \"file-abc123\",\n    \"file-abc456\"\n  ],\n  \"metadata\": {},\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  }\n}\nRetrieve run stepBeta\n\nGET\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/steps/{step_id}\n\nRetrieves a run step.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread to which the run and run step belongs.\n\nrun_id\nstring\nRequired\n\nThe ID of the run to which the run step belongs.\n\nstep_id\nstring\nRequired\n\nThe ID of the run step to retrieve.\n\nReturns\n\nThe run step object matching the specified ID.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n\ncurl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v1\"\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n{\n  \"id\": \"step_abc123\",\n  \"object\": \"thread.run.step\",\n  \"created_at\": 1699063291,\n  \"run_id\": \"run_abc123\",\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"type\": \"message_creation\",\n  \"status\": \"completed\",\n  \"cancelled_at\": null,\n  \"completed_at\": 1699063291,\n  \"expired_at\": null,\n  \"failed_at\": null,\n  \"last_error\": null,\n  \"step_details\": {\n    \"type\": \"message_creation\",\n    \"message_creation\": {\n      \"message_id\": \"msg_abc123\"\n    }\n  },\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  }\n}\nModify runBeta\n\nPOST\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs/{run_id}\n\nModifies a run.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread that was run.\n\nrun_id\nstring\nRequired\n\nThe ID of the run to modify.\n\nRequest body\nmetadata\nmap\nOptional\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n\nReturns\n\nThe modified run object matching the specified ID.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\ncurl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v1\" \\\n  -d '{\n    \"metadata\": {\n      \"user_id\": \"user_abc123\"\n    }\n  }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n\n{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699075072,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n  \"started_at\": 1699075072,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699075073,\n  \"last_error\": null,\n  \"model\": \"gpt-3.5-turbo\",\n  \"instructions\": null,\n  \"tools\": [\n    {\n      \"type\": \"code_interpreter\"\n    }\n  ],\n  \"file_ids\": [\n    \"file-abc123\",\n    \"file-abc456\"\n  ],\n  \"metadata\": {\n    \"user_id\": \"user_abc123\"\n  },\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  }\n}\nSubmit tool outputs to runBeta\n\nPOST\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/submit_tool_outputs\n\nWhen a run has the status: \"requires_action\" and required_action.type is submit_tool_outputs, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread to which this run belongs.\n\nrun_id\nstring\nRequired\n\nThe ID of the run that requires the tool output submission.\n\nRequest body\ntool_outputs\narray\nRequired\n\nA list of tools for which the outputs are being submitted.\n\nShow properties\nReturns\n\nThe modified run object matching the specified ID.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\ncurl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/submit_tool_outputs \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"OpenAI-Beta: assistants=v1\" \\\n  -d '{\n    \"tool_outputs\": [\n      {\n        \"tool_call_id\": \"call_abc123\",\n        \"output\": \"28C\"\n      }\n    ]\n  }'\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n\n{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699075592,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"queued\",\n  \"started_at\": 1699075592,\n  \"expires_at\": 1699076192,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"last_error\": null,\n  \"model\": \"gpt-4\",\n  \"instructions\": \"You tell the weather.\",\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"function\": {\n        \"name\": \"get_weather\",\n        \"description\": \"Determine weather in my location\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"location\": {\n              \"type\": \"string\",\n              \"description\": \"The city and state e.g. San Francisco, CA\"\n            },\n            \"unit\": {\n              \"type\": \"string\",\n              \"enum\": [\n                \"c\",\n                \"f\"\n              ]\n            }\n          },\n          \"required\": [\n            \"location\"\n          ]\n        }\n      }\n    }\n  ],\n  \"file_ids\": [],\n  \"metadata\": {},\n  \"usage\": null\n}\nCancel a runBeta\n\nPOST\n \nhttps://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/cancel\n\nCancels a run that is in_progress.\n\nPath parameters\nthread_id\nstring\nRequired\n\nThe ID of the thread to which this run belongs.\n\nrun_id\nstring\nRequired\n\nThe ID of the run to cancel.\n\nReturns\n\nThe modified run object matching the specified ID.\n\nExample request\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n\ncurl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v1\" \\\n  -X POST\nResponse\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1699076126,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"cancelling\",\n  \"started_at\": 1699076126,\n  \"expires_at\": 1699076726,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"last_error\": null,\n  \"model\": \"gpt-4\",\n  \"instructions\": \"You summarize books.\",\n  \"tools\": [\n    {\n      \"type\": \"retrieval\"\n    }\n  ],\n  \"file_ids\": [],\n  \"metadata\": {},\n  \"usage\": null\n}\nThe run objectBeta\n\nRepresents an execution run on a thread.\n\nid\nstring\n\nThe identifier, which can be referenced in API endpoints.\n\nobject\nstring\n\nThe object type, which is always thread.run.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the run was created.\n\nthread_id\nstring\n\nThe ID of the thread that was executed on as a part of this run.\n\nassistant_id\nstring\n\nThe ID of the assistant used for execution of this run.\n\nstatus\nstring\n\nThe status of the run, which can be either queued, in_progress, requires_action, cancelling, cancelled, failed, completed, or expired.\n\nrequired_action\nobject or null\n\nDetails on the action required to continue the run. Will be null if no action is required.\n\nShow properties\nlast_error\nobject or null\n\nThe last error associated with this run. Will be null if there are no errors.\n\nShow properties\nexpires_at\ninteger\n\nThe Unix timestamp (in seconds) for when the run will expire.\n\nstarted_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run was started.\n\ncancelled_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run was cancelled.\n\nfailed_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run failed.\n\ncompleted_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run was completed.\n\nmodel\nstring\n\nThe model that the assistant used for this run.\n\ninstructions\nstring\n\nThe instructions that the assistant used for this run.\n\ntools\narray\n\nThe list of tools that the assistant used for this run.\n\nShow possible types\nfile_ids\narray\n\nThe list of File IDs the assistant used for this run.\n\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n\nusage\nobject or null\n\nUsage statistics related to the run. This value will be null if the run is not in a terminal state (i.e. in_progress, queued, etc.).\n\nShow properties\nThe run object\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"created_at\": 1698107661,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n  \"started_at\": 1699073476,\n  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n  \"completed_at\": 1699073498,\n  \"last_error\": null,\n  \"model\": \"gpt-4\",\n  \"instructions\": null,\n  \"tools\": [{\"type\": \"retrieval\"}, {\"type\": \"code_interpreter\"}],\n  \"file_ids\": [],\n  \"metadata\": {},\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  }\n}\nThe run step objectBeta\n\nRepresents a step in execution of a run.\n\nid\nstring\n\nThe identifier of the run step, which can be referenced in API endpoints.\n\nobject\nstring\n\nThe object type, which is always thread.run.step.\n\ncreated_at\ninteger\n\nThe Unix timestamp (in seconds) for when the run step was created.\n\nassistant_id\nstring\n\nThe ID of the assistant associated with the run step.\n\nthread_id\nstring\n\nThe ID of the thread that was run.\n\nrun_id\nstring\n\nThe ID of the run that this run step is a part of.\n\ntype\nstring\n\nThe type of run step, which can be either message_creation or tool_calls.\n\nstatus\nstring\n\nThe status of the run step, which can be either in_progress, cancelled, failed, completed, or expired.\n\nstep_details\nobject\n\nThe details of the run step.\n\nShow possible types\nlast_error\nobject or null\n\nThe last error associated with this run step. Will be null if there are no errors.\n\nShow properties\nexpired_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.\n\ncancelled_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run step was cancelled.\n\nfailed_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run step failed.\n\ncompleted_at\ninteger or null\n\nThe Unix timestamp (in seconds) for when the run step completed.\n\nmetadata\nmap\n\nSet of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n\nusage\nobject or null\n\nUsage statistics related to the run step. This value will be null while the run step's status is in_progress.\n\nShow properties\nThe run step object\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n{\n  \"id\": \"step_abc123\",\n  \"object\": \"thread.run.step\",\n  \"created_at\": 1699063291,\n  \"run_id\": \"run_abc123\",\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"type\": \"message_creation\",\n  \"status\": \"completed\",\n  \"cancelled_at\": null,\n  \"completed_at\": 1699063291,\n  \"expired_at\": null,\n  \"failed_at\": null,\n  \"last_error\": null,\n  \"step_details\": {\n    \"type\": \"message_creation\",\n    \"message_creation\": {\n      \"message_id\": \"msg_abc123\"\n    }\n  },\n  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  }\n}\nCompletionsLegacy\n\nGiven a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our Chat Completions API to leverage our best and newest models. Most models that support the legacy Completions endpoint will be shut off on January 4th, 2024.\n\nCreate completionLegacy\n\nPOST\n \nhttps://api.openai.com/v1/completions\n\nCreates a completion for the provided prompt and parameters.\n\nRequest body\nmodel\nstring\nRequired\n\nID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them.\n\nprompt\nstring or array\nRequired\n\nThe prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.\n\nNote that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.\n\nbest_of\ninteger or null\nOptional\nDefaults to 1\n\nGenerates best_of completions server-side and returns the \"best\" (the one with the highest log probability per token). Results cannot be streamed.\n\nWhen used with n, best_of controls the number of candidate completions and n specifies how many to return – best_of must be greater than n.\n\nNote: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.\n\necho\nboolean or null\nOptional\nDefaults to false\n\nEcho back the prompt in addition to the completion\n\nfrequency_penalty\nnumber or null\nOptional\nDefaults to 0\n\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n\nSee more information about frequency and presence penalties.\n\nlogit_bias\nmap\nOptional\nDefaults to null\n\nModify the likelihood of specified tokens appearing in the completion.\n\nAccepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this tokenizer tool to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.\n\nAs an example, you can pass {\"50256\": -100} to prevent the <|endoftext|> token from being generated.\n\nlogprobs\ninteger or null\nOptional\nDefaults to null\n\nInclude the log probabilities on the logprobs most likely output tokens, as well the chosen tokens. For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.\n\nThe maximum value for logprobs is 5.\n\nmax_tokens\ninteger or null\nOptional\nDefaults to 16\n\nThe maximum number of tokens that can be generated in the completion.\n\nThe token count of your prompt plus max_tokens cannot exceed the model's context length. Example Python code for counting tokens.\n\nn\ninteger or null\nOptional\nDefaults to 1\n\nHow many completions to generate for each prompt.\n\nNote: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop.\n\npresence_penalty\nnumber or null\nOptional\nDefaults to 0\n\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n\nSee more information about frequency and presence penalties.\n\nseed\ninteger or null\nOptional\n\nIf specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result.\n\nDeterminism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend.\n\nstop\nstring / array / null\nOptional\nDefaults to null\n\nUp to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.\n\nstream\nboolean or null\nOptional\nDefaults to false\n\nWhether to stream back partial progress. If set, tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message. Example Python code.\n\nsuffix\nstring or null\nOptional\nDefaults to null\n\nThe suffix that comes after a completion of inserted text.\n\ntemperature\nnumber or null\nOptional\nDefaults to 1\n\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or top_p but not both.\n\ntop_p\nnumber or null\nOptional\nDefaults to 1\n\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n\nuser\nstring\nOptional\n\nA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.\n\nReturns\n\nReturns a completion object, or a sequence of completion objects if the request is streamed.\n\nNo streaming‍\nStreaming‍\nExample request\ngpt-3.5-turbo-instruct\ngpt-3.5-turbo-instruct\ncurl\nSelect library\ncurl\npython\nnode.js\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\ncurl https://api.openai.com/v1/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-3.5-turbo-instruct\",\n    \"prompt\": \"Say this is a test\",\n    \"max_tokens\": 7,\n    \"temperature\": 0\n  }'\nResponse\ngpt-3.5-turbo-instruct\ngpt-3.5-turbo-instruct\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n{\n  \"id\": \"cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7\",\n  \"object\": \"text_completion\",\n  \"created\": 1589478378,\n  \"model\": \"gpt-3.5-turbo-instruct\",\n  \"system_fingerprint\": \"fp_44709d6fcb\",\n  \"choices\": [\n    {\n      \"text\": \"\\n\\nThis is indeed a test\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\": \"length\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 5,\n    \"completion_tokens\": 7,\n    \"total_tokens\": 12\n  }\n}\nThe completion objectLegacy\n\nRepresents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).\n\nid\nstring\n\nA unique identifier for the completion.\n\nchoices\narray\n\nThe list of completion choices the model generated for the input prompt.\n\nShow properties\ncreated\ninteger\n\nThe Unix timestamp (in seconds) of when the completion was created.\n\nmodel\nstring\n\nThe model used for completion.\n\nsystem_fingerprint\nstring\n\nThis fingerprint represents the backend configuration that the model runs with.\n\nCan be used in conjunction with the seed request parameter to understand when backend changes have been made that might impact determinism.\n\nobject\nstring\n\nThe object type, which is always \"text_completion\"\n\nusage\nobject\n\nUsage statistics for the completion request.\n\nShow properties\nThe completion object\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n{\n  \"id\": \"cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7\",\n  \"object\": \"text_completion\",\n  \"created\": 1589478378,\n  \"model\": \"gpt-3.5-turbo\",\n  \"choices\": [\n    {\n      \"text\": \"\\n\\nThis is indeed a test\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\": \"length\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 5,\n    \"completion_tokens\": 7,\n    \"total_tokens\": 12\n  }\n}"
}