[
  {
    "title": "Use Spark in notebooks - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/use-apache-spark-azure-databricks/04-use-spark",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nUse Spark in notebooks\n6 minutes\n\nYou can run many different kinds of application on Spark, including code in Python or Scala scripts, Java code compiled as a Java Archive (JAR), and others. Spark is commonly used in two kinds of workload:\n\nBatch or stream processing jobs to ingest, clean, and transform data - often running as part of an automated pipeline.\nInteractive analytics sessions to explore, analyze, and visualize data.\nRunning Spark code in notebooks\n\nAzure Databricks includes an integrated notebook interface for working with Spark. Notebooks provide an intuitive way to combine code with Markdown notes, commonly used by data scientists and data analysts. The look and feel of the integrated notebook experience within Azure Databricks is similar to that of Jupyter notebooks - a popular open source notebook platform.\n\nNotebooks consist of one or more cells, each containing either code or markdown. Code cells in notebooks have some features that can help you be more productive, including:\n\nSyntax highlighting and error support.\nCode auto-completion​.\nInteractive data visualizations.\nThe ability to export results.\n\n Tip\n\nTo learn more about working with notebooks in Azure Databricks, see the Notebooks article in the Azure Databricks documentation.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Get to know Spark - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/use-apache-spark-azure-databricks/02-understand-spark",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nGet to know Spark\n4 minutes\n\nTo gain a better understanding of how to process and analyze data with Apache Spark in Azure Databricks, it's important to understand the underlying architecture.\n\nHigh-level overview\n\nFrom a high level, the Azure Databricks service launches and manages Apache Spark clusters within your Azure subscription. Apache Spark clusters are groups of computers that are treated as a single computer and handle the execution of commands issued from notebooks. Clusters enable processing of data to be parallelized across many computers to improve scale and performance. They consist of a Spark driver and worker nodes. The driver node sends work to the worker nodes and instructs them to pull data from a specified data source.\n\nIn Databricks, the notebook interface is typically the driver program. This driver program contains the main loop for the program and creates distributed datasets on the cluster, then applies operations to those datasets. Driver programs access Apache Spark through a SparkSession object regardless of deployment location.\n\nMicrosoft Azure manages the cluster, and auto-scales it as needed based on your usage and the setting used when configuring the cluster. Auto-termination can also be enabled, which allows Azure to terminate the cluster after a specified number of minutes of inactivity.\n\nSpark jobs in detail\n\nWork submitted to the cluster is split into as many independent jobs as needed. This is how work is distributed across the Cluster's nodes. Jobs are further subdivided into tasks. The input to a job is partitioned into one or more partitions. These partitions are the unit of work for each slot. In between tasks, partitions may need to be reorganized and shared over the network.\n\nThe secret to Spark's high performance is parallelism. Scaling vertically (by adding resources to a single computer) is limited to a finite amount of RAM, Threads and CPU speeds; but clusters scale horizontally, adding new nodes to the cluster as needed.\n\nSpark parallelizes jobs at two levels:\n\nThe first level of parallelization is the executor - a Java virtual machine (JVM) running on a worker node, typically, one instance per node.\nThe second level of parallelization is the slot - the number of which is determined by the number of cores and CPUs of each node.\nEach executor has multiple slots to which parallelized tasks can be assigned.\n\nThe JVM is naturally multi-threaded, but a single JVM, such as the one coordinating the work on the driver, has a finite upper limit. By splitting the work into tasks, the driver can assign units of work to *slots in the executors on worker nodes for parallel execution. Additionally, the driver determines how to partition the data so that it can be distributed for parallel processing. So, the driver assigns a partition of data to each task so that each task knows which piece of data it is to process. Once started, each task will fetch the partition of data assigned to it.\n\nJobs and stages\n\nDepending on the work being performed, multiple parallelized jobs may be required. Each job is broken down into stages. A useful analogy is to imagine that the job is to build a house:\n\nThe first stage would be to lay the foundation.\nThe second stage would be to erect the walls.\nThe third stage would be to add the roof.\n\nAttempting to do any of these steps out of order just doesn't make sense, and may in fact be impossible. Similarly, Spark breaks each job into stages to ensure everything is done in the right order.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Introduction - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/use-apache-spark-azure-databricks/01-introduction",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nIntroduction\n1 minute\n\nAzure Databricks offers a highly scalable platform for data analytics and processing using Apache Spark.\n\nSpark is a flexible platform that supports many different programming languages and APIs. Most data processing and analytics tasks can be accomplished using the Dataframe API, which is what we'll focus on in this module.\n\nIn this module, you'll learn how to:\n\nDescribe key elements of the Apache Spark architecture.\nCreate and configure a Spark cluster.\nDescribe use cases for Spark.\nUse Spark to process and analyze data stored in files.\nUse Spark to visualize data.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Use Apache Spark in Azure Databricks - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/use-apache-spark-azure-databricks/",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nUse Apache Spark in Azure Databricks\nModule\n9 Units\nFeedback\nIntermediate\nData Engineer\nAzure Databricks\n\nAzure Databricks is built on Apache Spark and enables data engineers and analysts to run Spark jobs to transform, analyze and visualize data at scale.\n\nLearning objectives\n\nIn this module, you'll learn how to:\n\nDescribe key elements of the Apache Spark architecture.\nCreate and configure a Spark cluster.\nDescribe use cases for Spark.\nUse Spark to process and analyze data stored in files.\nUse Spark to visualize data.\nAdd\nPrerequisites\n\nBefore starting this module, you should have a basic knowledge of Azure Databricks. Consider completing the previous modules in the Data Engineering with Azure Databricks learning path before this one.\n\nIntroduction\nmin\nGet to know Spark\nmin\nCreate a Spark cluster\nmin\nUse Spark in notebooks\nmin\nUse Spark to work with data files\nmin\nVisualize data\nmin\nExercise - Use Spark in Azure Databricks\nmin\nKnowledge check\nmin\nSummary\nmin\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Summary - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-databricks/07-summary",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nSummary\n1 minute\n\nAzure Databricks is a scalable platform for data analytics in Microsoft Azure. You can use Azure Databricks to build highly scalable solutions for data science and engineering, machine learning, and SQL-based data analytics.\n\nIn this module, you learned how to:\n\nProvision an Azure Databricks workspace.\nIdentify core workloads and personas for Azure Databricks.\nDescribe key concepts of an Azure Databricks solution.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Exercise - Explore Azure Databricks - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-databricks/05-exercise-explore-databricks",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nLearn  Training  Browse  Explore Azure Databricks \nAdd\nPrevious\nUnit 5 of 7\nNext\nExercise - Explore Azure Databricks\nCompleted\n100 XP\n30 minutes\n\nNow it's your chance to explore Azure Databricks for yourself. In this exercise, you'll use a provided script to provision an Azure Databricks workspace in your Azure subscription; and then use the Azure Databricks portal to create a Spark cluster and perform some common data analytics tasks.\n\n Note\n\nTo complete this lab, you will need an Azure subscription in which you have administrative access.\n\nLaunch the exercise and follow the instructions.\n\nNext unit: Knowledge check\n\nContinue\n\nHaving an issue? We can help!\n\nFor issues related to this module, explore existing questions using the #azure training tag or Ask a question ​on Microsoft Q&A .\nFor issues related to Certifications and Exams, post on Credentials Support Forum or visit our Credentials Help.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Knowledge check - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-databricks/06-knowledge-check",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nKnowledge check\n3 minutes\n1. \n\nYou plan to create an Azure Databricks workspace and use it to work with a SQL Warehouse. Which of the following pricing tiers can you select?\n\n \n\nEnterprise\n\nStandard\n\nPremium\n\n2. \n\nYou've created an Azure Databricks workspace in which you plan to use code to process data files. What must you create in the workspace?\n\n \n\nA SQL Warehouse\n\nA Spark cluster\n\nA Windows Server virtual machine\n\n3. \n\nYou want to use Python code to interactively explore data in a text file that you've uploaded to your Azure Databricks workspace. What should you create?\n\n \n\nA SQL query\n\nAn Azure function\n\nA Notebook\n\nCheck your answers\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Understand key concepts - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-databricks/04-key-concepts",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nLearn  Training  Browse  Explore Azure Databricks \nAdd\nPrevious\nUnit 4 of 7\nNext\nUnderstand key concepts\nCompleted\n100 XP\n3 minutes\n\nAzure Databricks is an amalgamation of multiple technologies that enable you to work with data at scale. Before using Azure Databricks, there are some key concepts that you should understand.\n\nApache Spark clusters - Spark is a distributed data processing solution that makes use of clusters to scale processing across multiple compute nodes. Each Spark cluster has a driver node to coordinate processing jobs, and one or more worker nodes on which the processing occurs. This distributed model enables each node to operate on a subset of the job in parallel; reducing the overall time for the job to complete. To learn more about clusters in Azure Databricks, see Clusters in the Azure Databricks documentation.\nDatabricks File System (DBFS) - While each cluster node has its own local file system (on which operating system and other node-specific files are stored), the nodes in a cluster have access to a shared, distributed file system in which they can access and operate on data files. The Databricks File System (DBFS) enables you to mount cloud storage and use it to work with and persist file-based data. To learn more about DBFS, see Databricks File System (DBFS) in the Azure Databricks documentation.\nNotebooks - One of the most common ways for data analysts, data scientists, data engineers, and developers to work with Spark is to write code in notebooks. Notebooks provide an interactive environment in which you can combine text and graphics in Markdown format with cells containing code that you run interactively in the notebook session. To learn more about notebooks, see Notebooks in the Azure Databricks documentation.\nHive metastore - Hive is an open source technology used to define a relational abstraction layer of tables over file-based data. The tables can then be queried using SQL syntax. The table definitions and details of the file system locations on which they're based is stored in the metastore for a Spark cluster. A Hive metastore is created for each cluster when it's created, but you can configure a cluster to use an existing external metastore if necessary - see Metastores in the Azure Databricks documentation for more details.\nDelta Lake - Delta Lake builds on the relational table schema abstraction over files in the data lake to add support for SQL semantics commonly found in relational database systems. Capabilities provided by Delta Lake include transaction logging, data type constraints, and the ability to incorporate streaming data into a relational table. To learn more about Delta Lake, see Delta Lake Guide in the Azure Databricks documentation.\nSQL Warehouses - SQL Warehouses are relational compute resources with endpoints that enable client applications to connect to an Azure Databricks workspace and use SQL to work with data in tables. The results of SQL queries can be used to create data visualizations and dashboards to support business analytics and decision making. SQL Warehouses are only available in premium tier Azure Databricks workspaces. To learn more about SQL Warehouses, see SQL Warehouses in the Azure Databricks documentation.\nNext unit: Exercise - Explore Azure Databricks\n\nContinue\n\nHaving an issue? We can help!\n\nFor issues related to this module, explore existing questions using the #azure training tag or Ask a question ​on Microsoft Q&A .\nFor issues related to Certifications and Exams, post on Credentials Support Forum or visit our Credentials Help.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Identify Azure Databricks workloads - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-databricks/03-workloads",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nIdentify Azure Databricks workloads\n3 minutes\n\nAzure Databricks is a comprehensive platform that offers many data processing capabilities. While you can use the service to support any workload that requires scalable data processing, Azure Databricks is optimized for three specific types of data workload and associated user personas:\n\nData Science and Engineering\nMachine Learning\nSQL*\n\n*SQL workloads are only available in premium tier workspaces.\n\nData Science and Engineering\n\nAzure Databricks provides Apache Spark based processing and analysis of large volumes of data in a data lake. Data engineers, data scientists, and data analysts can use interactive notebooks to run code in Python, Scala, SparkSQL, or other languages to cleanse, transform, aggregate, and analyze data.\n\nMachine Learning\n\nAzure Databricks supports machine learning workloads that involve data exploration and preparation, training and evaluating machine learning models, and serving models to generate predictions for applications and analyses. Data scientists and ML engineers can use AutoML to quickly train predictive models, or apply their skills with common machine learning frameworks such as SparkML, Scikit-Learn, PyTorch, and Tensorflow. They can also manage the end-to-end machine learning lifecycle with MLFlow.\n\nSQL\n\nAzure Databricks supports SQL-based querying for data stored in tables in a SQL Warehouse. This capability enables data analysts to query, aggregate, summarize, and visualize data using familiar SQL syntax and a wide range of SQL-based data analytical tools.\n\n Note\n\nSQL Warehouses are only available in premium Azure Databricks workspaces.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Introduction - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-databricks/01-introduction",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nIntroduction\n1 minute\n\nAzure Databricks is a fully managed, cloud-based data analytics platform, which empowers developers to accelerate AI and innovation by simplifying the process of building enterprise-grade data applications. Built as a joint effort by Microsoft and the team that started Apache Spark, Azure Databricks provides data science, engineering, and analytical teams with a single platform for big data processing and machine learning.\n\nBy combining the power of Databricks, an end-to-end, managed Apache Spark platform optimized for the cloud, with the enterprise scale and security of Microsoft's Azure platform, Azure Databricks makes it simple to run large-scale Spark workloads.\n\nIn this module, you'll learn how to:\n\nProvision an Azure Databricks workspace.\nIdentify core workloads and personas for Azure Databricks.\nDescribe key concepts of an Azure Databricks solution.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Get started with Azure Databricks - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-databricks/02-azure-databricks",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nGet started with Azure Databricks\n3 minutes\n\nAzure Databricks is a cloud-based distributed platform for data processing built on Apache Spark. Databricks was designed to unify data science, data engineering, and business data analytics on Spark by creating an easy to use environment that enables users to spend more time working effectively with data, and less time focused on managing clusters and infrastructure. As the platform has evolved, it has kept up to date with the latest advances in the Spark runtime and added usability features to support common data workloads in a single, centrally managed interface.\n\nAzure Databricks is hosted on the Microsoft Azure cloud platform, and integrated with Azure services such as Microsoft Entra ID, Azure Storage, Azure Synapse Analytics, and Azure Machine Learning. Organizations can apply their existing capabilities with the Databricks platform, and build fully integrated data analytics solutions that work with cloud infrastructure used by other enterprise applications.\n\nCreating an Azure Databricks workspace\n\nTo use Azure Databricks, you must create an Azure Databricks workspace in your Azure subscription. You can accomplish this by:\n\nUsing the Azure portal user interface.\nUsing an Azure Resource Manager (ARM) or Bicep template.\nUsing the New-AzDatabricksWorkspace Azure PowerShell cmdlet\nUsing the az databricks workspace create Azure command line interface (CLI) command.\n\nWhen you create a workspace, you must specify one of the following pricing tiers:\n\nStandard - Core Apache Spark capabilities with Microsoft Entra integration.\nPremium - Role-based access controls and other enterprise-level features.\nTrial - A 14-day free trial of a premium-level workspace\n\nUsing the Azure Databricks portal\n\nAfter you've provisioned an Azure Databricks workspace, you can use the Azure Databricks portal to work with data and compute resources. The Azure Databricks portal is a web-based user interface through which you can create and manage workspace resources (such as Spark clusters) and use notebooks and queries to work with data in files and tables.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Explore Azure Databricks - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-databricks/",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nLearn  Training  Browse \n800 XP\nExplore Azure Databricks\n44 min\nModule\n7 Units\nFeedback\nIntermediate\nData Engineer\nAzure Databricks\n\nAzure Databricks is a cloud service that provides a scalable platform for data analytics using Apache Spark.\n\nLearning objectives\n\nIn this module, you'll learn how to:\n\nProvision an Azure Databricks workspace.\nIdentify core workloads and personas for Azure Databricks.\nDescribe key concepts of an Azure Databricks solution.\nStart\nAdd\nPrerequisites\n\nBefore starting this module, you should have a fundamental knowledge of data analytics concepts. Consider completing Azure Data Fundamentals certification before starting this module.\n\nThis module is part of these learning paths\nData engineering with Azure Databricks\nMachine learning with Azure Databricks\nIntroduction\n1 min\nGet started with Azure Databricks\n3 min\nIdentify Azure Databricks workloads\n3 min\nUnderstand key concepts\n3 min\nExercise - Explore Azure Databricks\n30 min\nKnowledge check\n3 min\nSummary\n1 min\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Knowledge check - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/integrate-microsoft-purview-azure-synapse-analytics/07-knowledge-check",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nKnowledge check\n4 minutes\n1. \n\nYou want to scan data assets in a dedicated SQL pool in your Azure Synapse Analytics workspace. What kind of source should you register in Microsoft Purview?\n\n \n\nAzure Synapse Analytics\n\nAzure Data Lake Storage Gen2\n\nAzure SQL Database\n\n2. \n\nYou want to scan data assets in the default data lake used by your Azure Synapse Analytics workspace. What kind of source should you register in Microsoft Purview?\n\n \n\nAzure Synapse Analytics\n\nAzure Data Lake Storage Gen2\n\nAzure Cosmos DB\n\n3. \n\nYou want data analysts using Synapse Studio to be able to find data assets that are registered in a Microsoft Purview collection. What should you do?\n\n \n\nRegister an Azure Synapse Analytics source in the Purview account\n\nAdd a Data Explorer pool to the Synapse Workspace\n\nConnect the Purview account to the Synapse analytics workspace\n\n4. \n\nWhich of the following pipeline activities records data lineage data in a connected Purview account?\n\n \n\nGet Metadata\n\nCopy Data\n\nLookup\n\nCheck your answers\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Summary - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/integrate-microsoft-purview-azure-synapse-analytics/08-summary",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nSummary\n1 minute\n\nComprehensive data governance is an important element of an enterprise data analytics solution. By combining Azure Synapse Analytics and Microsoft Purview, you can improve data discoverability while addressing data trustworthiness and compliance requirements across your data estate.\n\nIn this module you learned how to:\n\nCatalog Azure Synapse Analytics database assets in Microsoft Purview.\nConfigure Microsoft Purview integration in Azure Synapse Analytics.\nSearch the Microsoft Purview catalog from Synapse Studio.\nTrack data lineage in Azure Synapse Analytics pipelines activities.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Exercise - Integrate Azure Synapse Analytics and Microsoft Purview - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/integrate-microsoft-purview-azure-synapse-analytics/06-exercise-synapse-purview",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nExercise - Integrate Azure Synapse Analytics and Microsoft Purview\n40 minutes\n\nNow it's your chance to explore integration between Microsoft Purview and Azure Synapse Analytics for yourself. In this exercise, you'll use a provided script to provision an Azure Synapse Analytics workspace and a Microsoft Purview account in your Azure subscription; and then you'll catalog data assets in your Azure Synapse Analytics workspace and data lake before connecting the Purview account to the workspace to support data discovery and lineage tracking.\n\n Note\n\nTo complete this lab, you will need an Azure subscription in which you have administrative access.\n\nLaunch the exercise and follow the instructions.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Track data lineage in pipelines - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/integrate-microsoft-purview-azure-synapse-analytics/05-track-data-lineage",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nTrack data lineage in pipelines\n4 minutes\n\nIn a typical large-scale analytics solution, data is transferred and transformed across multiple systems until it's loaded into an analytical data store for reporting and analysis. Tracking the lineage of data as moves across the enterprise is an important factor in determining the provenance, trustworthiness, and recency of data assets used to inform analysis and decision making.\n\nGenerate and view data lineage information\n\nIn Azure Synapse Analytics, data movement and transformation is managed by using pipelines, which consist of an orchestrated set of activities that operate on data. The design and implementation of pipelines is too large a subject to cover in depth in this module, but a key point to be aware of is that there are two activity types available in Synapse Analytics pipelines that automatically generate data lineage information in a connected Purview catalog:\n\nThe Copy Data activity\nThe Data Flow activity\n\nRunning a pipeline that includes either of these activities in a workspace with a connected Purview account will result in the creation or update of data assets with lineage information. The assets recorded include:\n\nThe source from which the data is extracted.\nThe activity used to transfer the data.\nThe destination where the data is stored.\n\nIn the Microsoft Purview Governance Portal, you can open the assets in the Purview catalog, and view the lineage information as shown here:\n\nYou can also view the lineage for a pipeline activity in Synapse Studio.\n\n Tip\n\nFor more information about tracking data lineage for Azure Synapse Analytics pipelines in Microsoft Purview, see How to get lineage from Azure Synapse Analytics into Microsoft Purview.\n\nYou'll get a chance to generate and view data lineage from a Synapse Analytics pipeline in the exercise later in this module.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Search a Purview catalog in Synapse Studio - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/integrate-microsoft-purview-azure-synapse-analytics/04-search-purview",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nSearch a Purview catalog in Synapse Studio\n4 minutes\n\nAfter connecting an Azure Synapse Analytics workspace to a Microsoft Purview account, you can search the Purview catalog from Synapse Studio. This ability to discover and examine data assets from across the enterprise can greatly assist data engineers, data analysts, and other consumers of data by providing a curated catalog of documented data sources for analysis and reporting.\n\nSearch the Purview catalog in Synapse Studio\n\nYou can search the catalog from a connected Purview account by using the Search bar in the Data, Develop, or Integrate pages in Synapse Studio, as shown here:\n\nThe search results interface, and the details for each asset found reflect the user interface in the Microsoft Purview Governance Portal, ensuring that the data discovery and examination experience in Synapse Studio is consistent for users of Microsoft Purview in its own portal.\n\n Tip\n\nFor more information about searching the Purview catalog in Synapse Studio, see Discover, connect, and explore data in Synapse using Microsoft Purview.\n\nYou'll get a chance to try searching a connected Purview account for yourself in the exercise later in this module.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Connect Microsoft Purview to an Azure Synapse Analytics workspace - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/integrate-microsoft-purview-azure-synapse-analytics/03-configure-purview-integration",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nConnect Microsoft Purview to an Azure Synapse Analytics workspace\n5 minutes\n\nSo far, you've learned how you can use Azure Synapse Analytics data stores as sources for a Microsoft Purview catalog; which is similar in most respects to using any other data source.\n\nWhat sets Azure Synapse Analytics apart from many other data sources is the ability to configure direct integration between an Azure Synapse Analytics workspace and a Microsoft Purview account. By linking your workspace to a Purview account, you can:\n\nSearch the Purview catalog in the Synapse Studio user interface.\nPush details of data pipeline activities to Purview in order to track data lineage information.\nConnect a Purview account to a Synapse Analytics workspace\n\nYou connect a Microsoft Purview account to an Azure Synapse Analytics workspace on the Manage page of Synapse Studio, as shown here:\n\nSecurity considerations\n\nTo connect a Purview account by using the Synapse Studio interface, you require Collection Administrator access to the Purview account's root collection. After successfully connecting the account, the managed identity used by your Azure Synapse Analytics workspace will be added to the collection's Data Curator role.\n\nIf your Microsoft Purview account is behind a firewall, you need to create a managed endpoint, and configure the connection to access Purview using that endpoint. For more information, see Access a secured Microsoft Purview account from Azure Synapse Analytics.\n\n Tip\n\nTo learn more about connecting Azure Synapse Analytics to Microsoft Purview, see QuickStart: Connect a Synapse workspace to a Microsoft Purview account.\n\nYou'll get a chance to connect an Azure Synapse Analytics workspace to a Microsoft Purview account in the exercise later in this module.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Catalog Azure Synapse Analytics data assets in Microsoft Purview - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/integrate-microsoft-purview-azure-synapse-analytics/02-catalog-azure-synapse",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nCatalog Azure Synapse Analytics data assets in Microsoft Purview\n8 minutes\n\nAzure Synapse Analytics is a platform for cloud-scale analytics workloads that process data in multiple sources; including:\n\nRelational databases in serverless and dedicated SQL pools\nFiles in Azure Data Lake Storage Gen2\n\nA comprehensive data analytics solution can include many folders and files in a data lake, and multiple databases that each contain many tables, each with multiple fields. For a data analyst, finding and understanding the data assets associated with a Synapse Analytics workspace can present a significant challenge before any analysis or reporting can even begin.\n\nMicrosoft Purview can help in this scenario by cataloging the data assets in a data map, and enabling data stewards to add metadata, categorization, subject matter contact details, and other information that helps data analysts identify and understand data.\n\nConfigure data access for Microsoft Purview\n\nIn order to scan the data assets in the data lake storage and databases used in your Azure Synapse Workspace, Microsoft Purview must have appropriate permissions to read the data. In practice, this means that the account used by your Microsoft Purview account (usually a system-assigned managed identity that is created when Microsoft Purview is provisioned) needs to be a member of the appropriate role-based access control (RBAC) and database roles.\n\nThe diagram shows that Microsoft Purview requires role membership that permits the following access:\n\nRead access to the Azure Synapse workspace (achieved through membership of the Reader role for the Azure Synapse Workspace resource in the Azure subscription).\nRead access to each SQL database that will be scanned (achieved through membership of the db_datareader fixed database role in each database).\nRead access to data lake storage (achieved through membership of the Storage Blob Data Reader role for the Azure Storage account hosting the Azure Data Lake Storage Gen2 container for the data lake).\n\n Tip\n\nLearn more:\n\nFor more information about RBAC in Microsoft Azure, see What is Azure role-based access control (Azure RBAC)?\nFor more information about database-level roles in Azure Synapse Analytics SQL pools, see Database-level roles.\n\nYou'll get a chance to assign RBAC and SQL database role membership to support Microsoft Purview data access for yourself in the exercise later in this module.\n\nRegister and scan data sources\n\nMicrosoft Purview supports the creation of a data map that catalogs data assets in collections by scanning registered sources. Collections form a hierarchy of logical groupings of related data assets, under a root collection that is created when you provision a Microsoft Purview account. You can use the Microsoft Purview Governance Portal to create and manage collections in your account.\n\nTo include assets from a particular data source, you need to register the source in a collection. Microsoft Purview supports many kinds of source, including:\n\nAzure Synapse Analytics - One or more SQL databases in a Synapse Analytics workspace.\nAzure Data Lake Storage Gen2 - Blob containers used to host folders and files in a data lake.\n\nTo catalog assets used in an Azure Synapse Analytics workspace, you can register one or both of these sources in a collection, as shown here:\n\nAfter registering the sources where your data assets are stored, you can scan each source to catalog the assets it contains. You can scan each source interactively, and you can schedule period scans to keep the data map up to date.\n\n Tip\n\nTo learn more about registering and scanning sources, see Scans and ingestion in Microsoft Purview.\n\nYou'll get a chance to register and scan sources for an Azure Synapse Analytics workspace in the exercise later in this module.\n\nView and manage cataloged data assets\n\nAs each scan finds data assets in the registered sources, they're added to the associated collection in the data catalog. You can query the data catalog in the Microsoft Purview Governance Portal to view and filter the data assets, as shown here:\n\nData assets include items in the registered data stores at multiple levels. For example, assets from an Azure Synapse Analytics source include databases, schemas, tables, and individual fields; and assets from an Azure Data Lake Storage Gen 2 source include containers, folders, and files.\n\nYou can view and edit the properties of each asset to add contextual information such as descriptions, contacts for expert help, and other useful metadata. Data assets can also be classified using built-in or custom classifications that match specific patterns of data field to common types of data - for example, passport numbers, credit card numbers, and others.\n\n Tip\n\nTo learn more about data asset classification, see Data classification in the Microsoft Purview governance portal.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Introduction - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/integrate-microsoft-purview-azure-synapse-analytics/01-introduction",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nIntroduction\n1 minute\n\nMicrosoft Purview is a cloud service that provides the basis of a data governance solution in which you can catalog, classify, and track data assets across a large-scale data estate.\n\nAzure Synapse Analytics is a cloud-scale data analytics suite that supports data ingestion and transformation, distributed big data processing and exploration with SQL and Spark, and enterprise data warehousing.\n\nWhen combined, Microsoft Purview and Azure Synapse Analytics can be used to create a comprehensive solution for reliable, massively scalable data analytics with rich data asset discovery and lineage tracking capabilities.\n\nIn this module you'll learn how to:\n\nCatalog Azure Synapse Analytics database assets in Microsoft Purview.\nConfigure Microsoft Purview integration in Azure Synapse Analytics.\nSearch the Microsoft Purview catalog from Synapse Studio.\nTrack data lineage in Azure Synapse Analytics pipelines activities.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Integrate Microsoft Purview and Azure Synapse Analytics - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/integrate-microsoft-purview-azure-synapse-analytics/",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nIntegrate Microsoft Purview and Azure Synapse Analytics\nModule\n8 Units\nFeedback\nIntermediate\nData Analyst\nData Engineer\nAzure Synapse Analytics\nMicrosoft Purview\n\nLearn how to integrate Microsoft Purview with Azure Synapse Analytics to improve data discoverability and lineage tracking.\n\nLearning objectives\n\nAfter completing this module, you'll be able to:\n\nCatalog Azure Synapse Analytics database assets in Microsoft Purview.\nConfigure Microsoft Purview integration in Azure Synapse Analytics.\nSearch the Microsoft Purview catalog from Synapse Studio.\nTrack data lineage in Azure Synapse Analytics pipelines activities.\nAdd\nPrerequisites\n\nBefore starting this module, you should be familiar with both Azure Synapse Analytics and Microsoft Purview. Consider completing the following modules before starting this one:\n\nIntroduction to Azure Synapse Analytics\nIntroduction to Microsoft Purview\nIntroduction\nmin\nCatalog Azure Synapse Analytics data assets in Microsoft Purview\nmin\nConnect Microsoft Purview to an Azure Synapse Analytics workspace\nmin\nSearch a Purview catalog in Synapse Studio\nmin\nTrack data lineage in pipelines\nmin\nExercise - Integrate Azure Synapse Analytics and Microsoft Purview\nmin\nKnowledge check\nmin\nSummary\nmin\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Summary - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/manage-power-bi-artifacts-use-microsoft-purview/6-summary",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nSummary\n2 minutes\n\nAs data grows in your organization, tracking its origins and evolution becomes more and more difficult. Microsoft Purview makes it possible to see end-to-end lineage of data sources both in Power BI and extending to the data platform.\n\nFrom an enterprise perspective, the ability to scan and view data across your entire Power BI tenant is critical. Microsoft Purview enables users to find trusted data and also to troubleshoot and understand dependencies across the analytics landscape.\n\nLearn more\nRegister and scan a Power BI tenant in Microsoft Purview\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Knowledge check - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/manage-power-bi-artifacts-use-microsoft-purview/5-knowledge-check",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nKnowledge check\n3 minutes\n\nChoose the best response for each of the questions below. Then select Check your answers.\n\nCheck your knowledge\n1. \n\nWhat are the prerequisite steps to register and scan a Power BI tenant in Microsoft Purview?\n\n \n\nSet up authentication between Purview and Power BI, and configure the Power BI tenant.\n\nSet up and deploy a Power BI data gateway.\n\nConfigure the Power BI tenant only.\n\n2. \n\nWhat steps are required in the Power BI admin portal to enable the scanning and display of enhanced metadata?\n\n \n\nThere are no other steps required. Enhanced metadata displays by default.\n\nEnable enhanced metadata scanning in the Azure portal.\n\nEnable an admin API setting in the Power BI admin portal.\n\n3. \n\nWhat details of an asset would be helpful in performing an impact analysis?\n\n \n\nLineage.\n\nProperties.\n\nSchema.\n\nCheck your answers\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "View Power BI metadata and lineage - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/manage-power-bi-artifacts-use-microsoft-purview/4-view-lineage",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nView Power BI metadata and lineage\n4 minutes\n\nPurview and Power BI together are powerful, enhancing the ability of the search and browse features to see both the schema and lineage of Power BI assets.\n\nExtend your search with enhanced metadata\n\nMetadata scanning facilitates governance by making it possible to catalog and report on the metadata of your organization's Power BI artifacts. The results of metadata scanning are displayed on the schema tab of the asset.\n\n Note\n\nMetadata scanning must be enabled in the Power BI admin portal. See Set up metadata scanning in your organization to learn more.\n\nAfter performing a search in the Purview Governance Portal, select a Power BI asset from your search result to see the sensitivity labels and endorsement metadata. Additional business metadata includes the dataset user configuration, create datetime, and description.\n\nUnder the Schema tab, you can see the list of all the tables, columns, and measures created inside the Power BI dataset.\n\nFor more detail, selecting a particular field within the schema tab will take you to the details for that field. You can then view the overview, properties, lineage, contacts, and related assets for that particular field.\n\nMetadata scanning requires no special license. It works for all of your tenant metadata, including items that are located in non-Premium workspaces.\n\nIf you'd like more information about assets, you also have the option open the Power BI dataset in the Power BI service for further analytics, root-cause investigation, impact analysis, management tasks, and dataset enrichment.\n\nExtend your search with lineage\n\nIf you're using the search and browse features in Microsoft Purview to find assets for reporting or to troubleshoot existing assets, you likely need more information on where data actually comes from, and what transformation steps it has undergone. The lineage view displays the flow of data from the source through to Power BI assets, including dataflows, datasets, reports, and dashboards.\n\nAlthough you can track data lineage in Power BI, this information is limited to the items in a single workspace. Lineage in Purview enables you to view the movement of data across more than one workspace, in a single view.\n\nLineage enables easy troubleshooting and deeper analysis of analytics projects. You're able to look both up and down-stream, to perform either root cause or impact analysis.\n\nFor example, you can detect the Azure Synapse Analytics pipeline that is responsible for the transformation of the data upstream of Power BI.\n\nIn the Purview Governance Portal, lineage is displayed from the asset you're currently viewing.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Search and browse Power BI assets - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/manage-power-bi-artifacts-use-microsoft-purview/3-search-browse-assets",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nSearch and browse Power BI assets\n4 minutes\n\nAfter data is registered and scanned, analysts and data consumers need to be able to find data, view enhanced metadata, and track data lineage. Search and browse in the Purview Data Catalog enables you to quickly find trustworthy data.\n\nAfter scanning your Power BI tenant, you'll see those assets appear in the search results, including underlying data sources.\n\nSearch the Microsoft Purview Data Catalog\n\nFrom the Microsoft Purview Governance Portal, you can type relevant keywords to start discovering assets. In this scenario, you're looking for \"sales.\"\n\nThe screenshot below displays the search result, with all assets corresponding to the keywords entered in the search engine. Notice the appearance of Power BI assets.\n\nYou can fine-tune your search using the filters on the left side of the page. Filters available include source type, keyword, object type, collection, classification, contact, label, and glossary term.\n\nBrowse the Microsoft Purview Data Catalog\n\nSearching for specific assets is great if you know what you're looking for, but analysts and data consumers may not know exactly how their data estate is structured. The browse experience enables you to explore what data is available, either by collection or through traversing the hierarchy of each data source in the catalog.\n\nTo access the browse experience, select Browse assets from the governance portal home page.\n\nYou can browse the data catalog either by collection or by source type, depending on your needs. Browsing by either collection or source type allows you to see assets you have access to. Once you find the asset you're looking for, you can select it to see details on schema, lineage, and a detailed classification list.\n\nUniquely, browsing by source type allows you to see the hierarchies of data sources using an explorer view. This is a helpful and familiar way to navigate to see lists of scanned assets.\n\n Note\n\nAssets in Purview are organized by collection and permissions are granted at collection level. Both searching and browsing require data reader permissions. See Access control in the Microsoft Purview Data Map for details on permissions.\n\nSelect an asset to see details about the properties, schema, lineage, contacts, and related assets.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Register and scan a Power BI tenant - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/manage-power-bi-artifacts-use-microsoft-purview/2-register-scan-tenant",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nRegister and scan a Power BI tenant\n4 minutes\n\nTo get an understanding of what is going on in your Power BI tenant, you can perform a full scan in Microsoft Purview to view the schema and lineage of assets across all workspaces. After, you can schedule incremental scans on workspaces that have changed since the previous scan.\n\nThere are a few pre-requisite steps required to scan your Power BI tenant in Microsoft Purview.\n\n Tip\n\nIf you need to create a Microsoft Purview account, see the quickstart guide to create a Microsoft Purview account in the Azure Portal.\n\nEstablish a connection between Microsoft Purview and Power BI\n\nMicrosoft Purview can connect to and scan Power BI either in the same tenant or across tenants. You'll need to set up authentication either by using a Managed Identity or a Delegated Authentication.\n\n Note\n\nSee Register and scan a Power BI tenant to learn more about the set-up and authentication of Power BI connections in same and cross-tenant scenarios.\n\nAuthenticate to Power BI tenant\n\nGive Microsoft Purview permissions to access your Power BI tenant.\n\nIf you're using Managed Identity to authenticate to Power BI, you'll need to create a security group in Microsoft Entra ID, and add your Microsoft Purview managed identity to this security group.\n\nIf a security group containing the Purview managed identity already exists, you can proceed to configuring the Power BI tenant.\n\nConfigure Power BI tenant\n\nNext you need to enable access to Power BI by Microsoft Purview in Power BI itself. This is done by enabling Allow service principals to use read-only Power BI admin APIs in the Power BI admin portal.\n\nRegister and scan Power BI\n\nNow that you've got access set up in both Microsoft Purview and Power BI, you can register and scan your Power BI tenant.\n\nAfter registering the Power BI tenant, initiate the scan by selecting New scan. Give your scan a name and step through the interface, where you'll be able to to exclude personal workspaces, confirm integration runtime and credentials, and select a collection. Test the connection to ensure authentication is set up properly.\n\n Note\n\nIf you're performing the scan, you must be both a Data Source Administrator and a Data Reader. See Access control in the Microsoft Purview Data Map for details on permissions.\n\nYou're able to track the progress of the scan in the data map, and once the scan is complete, you'll be able to search and browse the contents of your entire Power BI tenant!\n\nIf you're having any issues with scanning your Power BI tenant, see Troubleshoot Power BI tenant scans in Microsoft Purview for details and helpful hints.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Introduction - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/manage-power-bi-artifacts-use-microsoft-purview/1-introduction",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nIntroduction\n3 minutes\n\nAs the landscape of enterprise data continues to grow, it's critical to get an accurate view of your organization's data. Microsoft Purview and Power BI integration enables you to scan your entire Power BI tenant to search and browse Power BI assets, explore enhanced dataset metadata, trace end-to-end data lineage, and drill-down into datasets in Power BI for further analysis.\n\nLearning objectives\n\nIn this module, you will:\n\nRegister and scan a Power BI tenant.\nUse the search and browse functions to find data assets.\nDescribe the schema details and data lineage tracing of Power BI data assets.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Manage Power BI assets by using Microsoft Purview - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/manage-power-bi-artifacts-use-microsoft-purview/",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nManage Power BI assets by using Microsoft Purview\nModule\n6 Units\nFeedback\nBeginner\nData Analyst\nData Engineer\nPower BI\nMicrosoft Purview\n\nImprove data governance and asset discovery using Power BI and Microsoft Purview integration.\n\nLearning objectives\n\nBy the end of this module, you’ll be able to:\n\nRegister and scan a Power BI tenant.\nUse the search and browse functions to find data assets.\nDescribe the schema details and data lineage tracing of Power BI data assets.\nAdd\nPrerequisites\nFamiliarity with the Azure data ecosystem.\nIntroduction\nmin\nRegister and scan a Power BI tenant\nmin\nSearch and browse Power BI assets\nmin\nView Power BI metadata and lineage\nmin\nKnowledge check\nmin\nSummary\nmin\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Summary - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/catalog-data-artifacts-use-microsoft-purview/6-summary",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nSummary\n3 minutes\n\nData classification in Microsoft Purview is similar to subject tagging, and is used to mark and identify data of a specific type that's found within your data estate during scanning. Classification is based on the business context of the data.\n\nPrior to data classification and labeling, data assets must be registered and scanned in Microsoft Purview. After assets are registered, scanned, classified, and labeled, analysts and other data consumers can easily identify and use data assets.\n\nLearn more\nQuickstart: Create an account in the Microsoft Purview governance portal\nMicrosoft Purview how-to guides\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Knowledge check - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/catalog-data-artifacts-use-microsoft-purview/5-knowledge-check",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nKnowledge check\n3 minutes\n\nChoose the best response for each of the questions below. Then select Check your answers.\n\nCheck your knowledge\n1. \n\nWhat level are user permissions set at in Microsoft Purview?\n\n \n\nTenant.\n\nData catalog.\n\nCollection.\n\n2. \n\nWhat are the two types of classification in Microsoft Purview?\n\n \n\nSystem classifications and custom classifications.\n\nMicrosoft Information Protection Sensitivity Labels and system classifications.\n\nCustom classifications and user-defined classifications.\n\n3. \n\nIf a data analyst is looking for a specific resource for reporting, what should they use?\n\n \n\nPurview Data Catalog to search.\n\nThe business glossary.\n\nImport into Power BI and create a custom report.\n\nCheck your answers\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Search the data catalog - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/catalog-data-artifacts-use-microsoft-purview/4-search-data-catalog",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nSearch the data catalog\n3 minutes\n\nA data catalog search can empower business and data analysts to find and interpret data. The data catalog provides intelligent recommendations based on data relationships, business context, and search history. The Purview data catalog can assist data teams by adding business context to assets to drive analytics, AI and ML initiatives.\n\nThe data catalog can be searched by keyword, object type, collection, classification, contact, label, or assigned term. Results can then be sorted by relevance or name.\n\nFor more information about searching for trusted assets for reporting, see Discover trusted data using Microsoft Purview.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Classify and label data - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/catalog-data-artifacts-use-microsoft-purview/3-classify-data",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nClassify and label data\n6 minutes\n\nGlossary terms, classifications and labels are all annotations to a data asset. Each of them have a different meaning in the context of the data catalog.\n\nWhat is data classification?\n\nClassifications are annotations that can be assigned to entities. The flexibility of classifications enables you to use them for multiple scenarios such as:\n\nunderstanding the nature of data stored in the data assets\ndefining access control policies\n\nClassification is based on the business context of the data. For example, you might classify assets by Passport Number, Driver's License Number, Credit Card Number, SWIFT Code, Person’s Name, and so on. Microsoft Purview has more than 200 system classifiers today. Users can also define their own classifiers in the data catalog. As part of the scanning process, classifications are automatically detected and applied as metadata within the Purview Data Catalog.\n\nClassification rules\n\nIn Microsoft Purview, you can apply system or custom classifications on a file, table, or column asset. Microsoft Purview makes use of Regex patterns and bloom filters to classify data. These classifications are then associated with the metadata discovered in the Azure Purview Data Catalog.\n\nMetadata is used to help describe the data that is being scanned and made available in the catalog. During the configuration of a scan set, you can specify classification rules to apply during the scan that will also serve as metadata. The existing classification rules fall under five major categories:\n\nGovernment - covers attributes such as government identity cards, driver license numbers, passport numbers, etc.\nFinancial - covers attributes such as bank account numbers or credit card numbers.\nPersonal - personal information such as a person's age, date of birth, email address, phone number, etc.\nSecurity - attributes like passwords that may be stored.\nMiscellaneous - attributes not covered in the other categories.\nWhy classify data?\n\nA good data governance strategy includes a process to classify data to understand its level of confidentiality, determine if the data source is compliant with various regulations, or how long to retain it for. Classification in Microsoft Purview makes data assets easier to understand, search, and govern. Classification can also help you implement measures to protect sensitive data.\n\nOnce a classification is tagged to a data source after a scan, you can generate reports and insights to gain a stronger understanding of your data estate. Because classification is based on the business context of the data, it can help bridge the gap between the business and the data team.\n\nData classification: system vs. custom classification\n\nMicrosoft Purview supports both system and custom classifications. There are over +200 system classifications available in Microsoft Purview today. Data teams need to know that if necessary classifications aren't available out of the box, they can work with the data stewards to create custom classifications, to meet their own organizational data governance requirements.\n\n Important\n\nFor the entire list of available system classifications, see Supported classifications in Microsoft Purview.\n\nWho creates custom classifications?\n\nPurview Data Curators can create, update, and delete custom classifiers and classification rules. Purview Data Readers can only view classifiers and classification rules.\n\nIn practical terms, Data Curators may not be members of the data team. It is however critical that data team members understand classification to be able to successfully work together and govern data across an organization.\n\nWhat are data labels?\n\nThe Microsoft Purview Data Map supports labeling structured and unstructured data stored across various data sources. This may sound familiar to you from other Microsoft technologies - and may be known as sensitivity labels. The data map extends the use of sensitivity labels from Microsoft Purview Information Protection to assets stored in infrastructure cloud locations and structured data sources.\n\nLabels are defined in Microsoft Purview Information Protection, and you can extend the application to Microsoft Purview Data Catalog.\n\nThe screenshot below shows both data classification and label in the Microsoft Purview Data Catalog. You can see that this Azure SQL table has a column called “CreditCard”:\n\nClassified as “Credit Card Number” because scan detected numbers corresponding to credit card pattern rules.\nLabeled as “Confidential – Finance” because credit card number was defined in your organization as confidential information (and this label brings encryption).\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Register and scan data - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/catalog-data-artifacts-use-microsoft-purview/2-register-scan-data",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nRegister and scan data\n10 minutes\n\nRegistration and scanning of data enables discoverability of data across an estate.\n\nBefore you can register and scan data, it’s important to understand the concept of collections. In Microsoft Purview Data Catalog, collections are key concept because they drive permissions and asset protection. Collections are also used to understand data estate health and catalog usage and adoption, as featured in the data stewardship section of your Data Estate Insights.\n\nCollections\n\nThe data map is at the core of Microsoft Purview, which keeps an up-to-date map of assets and their metadata across your data estate. To hydrate the data map, you need to register and scan your data sources, which is done at the collection level. Collections support organizational mapping of metadata. By using collections, you can manage and maintain data sources, scans, and assets in a hierarchy instead of a flat structure. Collections allow you to build a custom hierarchical model of your data landscape based on how your organization plans to use Microsoft Purview to govern your landscape.\n\nCollections also provide a security boundary for your metadata in the data map. Access to collections, data sources, and metadata is set up and maintained based on the collection’s hierarchy in Microsoft Purview, following a least-privilege model:\n\nUsers have the minimum amount of access they need to do their jobs.\nUsers don't have access to sensitive data that they don't need.\n\nData sources are registered at the collection level. Scan results can then be sent to this collection or a sub collection. The image below displays the structure of a collection.\n\n Tip\n\nLearn more about Microsoft Purview collections architectures and best practices.\n\nRegister and scan data sources\n\nData governance use begins at collection level, with the registration of data sources in Microsoft Purview governance portal. Microsoft Purview supports an array of data sources. Data teams (analysts, engineers, and scientists) may not be actively registering and scanning data in Microsoft Purview, but it's critical that data consumers understand governance efforts. Registering and scanning assets requires Data Curator permissions.\n\n Important\n\nData registered and scanned in Microsoft Purview only collects metadata information. Data remains in its location and isn't migrated to any other platform.\n\nRegister a data source\n\nRegistering a data source is done from within the Azure portal. Once you have a Microsoft Purview service configured in Azure, you use the Microsoft Purview governance portal to register your data sources.\n\nTo register a data source, you'll select the icon to register a data source as displayed in the image below. Selecting this icon will give you access to all data source connectors.\n\nBelow is a small sample of available connectors in Microsoft Purview Data Catalog. See supported data sources and file types for an up-to-date list of supported data sources and connectors.\n\nRegistering a data source is straightforward, you need to complete the required fields. Authentication will be done during the scanning phase.\n\nEach type of data source you choose will require specific information to complete the registration. For example, if your data sources reside in your Azure subscription, you'll choose the necessary subscription and storage account name.\n\nScan a data source\n\nOnce you have data sources registered in the Microsoft Purview governance portal and displayed in the data map, you can set up scanning. The scanning process can be triggered to run immediately or can be scheduled to run on a periodic basis to keep your Microsoft Purview account up to date.\n\nScanning assets is as simple as selecting New scan from the resource as displayed in the data map.\n\nYou'll now need to configure your scan and assign the following details:\n\nAssign a friendly name.\nDefine which integration runtime to use to perform the scan.\nCreate credentials to authenticate to your registered data sources.\nChoose a collection to send scan results.\n\nAfter the basic configuration, you'll scope your scan, which allows you to choose just a specific zone of your data source. For instance, if you have a collection called “Raw” in your data map, you can define the scope to scan only the raw container of your data lake.\n\nAfter configuring and scoping your scan, you'll define the scan rule set. A scan rule set is a container for grouping a set of scan rules together so that you can easily associate them with a scan. For example, you might create a default scan rule set for each of your data source types, and then use these scan rule sets by default for all scans within your company. You might also want users with the right permissions to create other scan rule sets with different configurations based on business need.\n\nOnce a scan is complete, you can refer to the scan details to view information about the number of scans completed, assets detected, assets classified, Scan information. It’s a good place to monitor scan progress, including success or failure.\n\n Tip\n\nRefer to Scanning best practices for more information on scanning assets.\n\nRoles and permissions\n\nPermissions in Microsoft Purview are assigned at collection level. Collections are used to organize assets and sources and can be thought of as a logical grouping of data assets.\n\nData teams looking to discover and use data need to be assigned the Data Reader role in a collection in Microsoft Purview. The Data Reader role enables users to find assets, but doesn't enable users to edit anything. The Data Curator role is required to edit information about assets, assign classifications, and associate assets with glossary entries. To set up scans via the Microsoft Purview Governance Portal, individuals need to be either a data curator on the collection or data curator and data source administrator where the source is registered.\n\nWhen a Microsoft Purview account is created, it starts with a root collection that has the same name as the Microsoft Purview account itself. The creator of the Microsoft Purview account is automatically added as a Collection Admin, who can then assign Data Source Admin, Data Curator, and Data Reader on this root collection, and can edit and manage this collection.\n\n Tip\n\nLearn more about Microsoft Purview permissions and access.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Introduction - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/catalog-data-artifacts-use-microsoft-purview/1-introduction",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nIntroduction\n3 minutes\n\nThe Microsoft Purview Data Catalog offers a browse experience that enables users to explore available data. Users can explore the data catalog either by collection or through traversing the hierarchy of each data source. The first step in understanding the contents of your data map is registering and scanning data, after which you can classify data for easy identification of assets to use for reporting.\n\nLearning objectives\n\nIn this module, you will:\n\nDescribe asset classification in Microsoft Purview.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Catalog data artifacts by using Microsoft Purview - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/catalog-data-artifacts-use-microsoft-purview/",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nCatalog data artifacts by using Microsoft Purview\nModule\n6 Units\nFeedback\nBeginner\nData Analyst\nData Engineer\nMicrosoft Purview\n\nRegister, scan, catalog, and view data assets and their relevant details in Microsoft Purview.\n\nLearning objectives\n\nBy the end of this module, you’ll be able to:\n\nDescribe asset classification in Microsoft Purview.\nAdd\nPrerequisites\nExperience using the Azure data ecosystem.\nIntroduction\nmin\nRegister and scan data\nmin\nClassify and label data\nmin\nSearch the data catalog\nmin\nKnowledge check\nmin\nSummary\nmin\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  }
]