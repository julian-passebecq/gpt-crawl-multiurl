[
  {
    "title": "Compare Azure Data Lake Store to Azure Blob storage - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/introduction-to-azure-data-lake-storage/4-azure-data-lake-and-blob-storage",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nCompare Azure Data Lake Store to Azure Blob storage\n5 minutes\n\nIn Azure Blob storage, you can store large amounts of unstructured (\"object\") data in a flat namespace within a blob container. Blob names can include \"/\" characters to organize blobs into virtual \"folders\", but in terms of blob manageability the blobs are stored as a single-level hierarchy in a flat namespace.\n\nYou can access this data by using HTTP or HTTPs\n\nAzure Data Lake Storage Gen2 builds on blob storage and optimizes I/O of high-volume data by using a hierarchical namespace that organizes blob data into directories, and stores metadata about each directory and the files within it. This structure allows operations, such as directory renames and deletes, to be performed in a single atomic operation. Flat namespaces, by contrast, require several operations proportionate to the number of objects in the structure. Hierarchical namespaces keep the data organized, which yields better storage and retrieval performance for an analytical use case and lowers the cost of analysis.\n\n Tip\n\nIf you want to store data without performing analysis on the data, set the Hierarchical Namespace option to Disabled to set up the storage account as an Azure Blob storage account. You can also use blob storage to archive rarely used data or to store website assets such as images and media.\n\nIf you are performing analytics on the data, set up the storage account as an Azure Data Lake Storage Gen2 account by setting the Hierarchical Namespace option to Enabled. Because Azure Data Lake Storage Gen2 is integrated into the Azure Storage platform, applications can use either the Blob APIs or the Azure Data Lake Storage Gen2 file system APIs to access data.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Understand Azure Data Lake Storage Gen2 - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/introduction-to-azure-data-lake-storage/2-azure-data-lake-gen2",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nUnderstand Azure Data Lake Storage Gen2\n5 minutes\n\nA data lake is a repository of data that is stored in its natural format, usually as blobs or files. Azure Data Lake Storage is a comprehensive, massively scalable, secure, and cost-effective data lake solution for high performance analytics built into Azure.\n\nAzure Data Lake Storage combines a file system with a storage platform to help you quickly identify insights into your data. Data Lake Storage builds on Azure Blob storage capabilities to optimize it specifically for analytics workloads. This integration enables analytics performance, the tiering and data lifecycle management capabilities of Blob storage, and the high-availability, security, and durability capabilities of Azure Storage.\n\nBenefits\n\nData Lake Storage is designed to deal with this variety and volume of data at exabyte scale while securely handling hundreds of gigabytes of throughput. With this, you can use Data Lake Storage Gen2 as the basis for both real-time and batch solutions.\n\nHadoop compatible access\n\nA benefit of Data Lake Storage is that you can treat the data as if it's stored in a Hadoop Distributed File System (HDFS). With this feature, you can store the data in one place and access it through compute technologies including Azure Databricks, Azure HDInsight, and Azure Synapse Analytics without moving the data between environments. The data engineer also has the ability to use storage mechanisms such as the parquet format, which is highly compressed and performs well across multiple platforms using an internal columnar storage.\n\nSecurity\n\nData Lake Storage supports access control lists (ACLs) and Portable Operating System Interface (POSIX) permissions that don't inherit the permissions of the parent directory. In fact, you can set permissions at a directory level or file level for the data stored within the data lake, providing a much more secure storage system. This security is configurable through technologies such as Hive and Spark or utilities such as Azure Storage Explorer, which runs on Windows, macOS, and Linux. All data that is stored is encrypted at rest by using either Microsoft or customer-managed keys.\n\nPerformance\n\nAzure Data Lake Storage organizes the stored data into a hierarchy of directories and subdirectories, much like a file system, for easier navigation. As a result, data processing requires less computational resources, reducing both the time and cost.\n\nData redundancy\n\nData Lake Storage takes advantage of the Azure Blob replication models that provide data redundancy in a single data center with locally redundant storage (LRS), or to a secondary region by using the Geo-redundant storage (GRS) option. This feature ensures that your data is always available and protected if catastrophe strikes.\n\n Tip\n\nWhenever planning for a data lake, a data engineer should give thoughtful consideration to structure, data governance, and security. This should include consideration of factors that can influence lake structure and organization, such as:\n\nTypes of data to be stored\nHow the data will be transformed\nWho should access the data\nWhat are the typical access patterns\n\nThis approach will help determine how to plan for access control governance across your lake. Data engineers should be proactive in ensuring that the lake doesn't become the proverbial data swamp which becomes inaccessible and non-useful to users due to the lack of data governance and data quality measures. Establishing a baseline and following best practices for Azure Data Lake will help ensure a proper and robust implementation that will allow the organization to grow and gain insight to achieve more.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Introduction - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/introduction-to-azure-data-lake-storage/1-introduction",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nIntroduction\n1 minute\n\nMany organizations have spent the last two decades building data warehouses and business intelligence (BI) solutions based on relational database systems. Many BI solutions have lost out on opportunities to store unstructured data due to cost and complexity in these types of data in databases.\n\nData lakes have become a common solution to this problem. A data lake provides file-based storage, usually in a distributed file system that supports high scalability for massive volumes of data. Organizations can store structured, semi-structured, and unstructured files in the data lake and then consume them from there in big data processing technologies, such as Apache Spark.\n\nAzure Data Lake Storage Gen2 provides a cloud-based solution for data lake storage in Microsoft Azure, and underpins many large-scale analytics solutions built on Azure.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Introduction to Azure Data Lake Storage Gen2 - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/introduction-to-azure-data-lake-storage/",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nIntroduction to Azure Data Lake Storage Gen2\nModule\n8 Units\nFeedback\nIntermediate\nData Engineer\nAzure\nAzure Data Lake\n\nData lakes are a core element of data analytics architectures. Azure Data Lake Storage Gen2 provides a scalable, secure, cloud-based solution for data lake storage.\n\nLearning objectives\n\nIn this module you will learn how to:\n\nDescribe the key features and benefits of Azure Data Lake Storage Gen2\nEnable Azure Data Lake Storage Gen2 in an Azure Storage account\nCompare Azure Data Lake Storage Gen2 and Azure Blob storage\nDescribe where Azure Data Lake Storage Gen2 fits in the stages of analytical processing\nDescribe how Azure data Lake Storage Gen2 is used in common analytical workloads\nAdd\nPrerequisites\n\nBefore starting this module, you should have completed the Microsoft Azure Data Fundamentals certification or have equivalent knowledge and experience.\n\nIntroduction\nmin\nUnderstand Azure Data Lake Storage Gen2\nmin\nEnable Azure Data Lake Storage Gen2 in Azure Storage\nmin\nCompare Azure Data Lake Store to Azure Blob storage\nmin\nUnderstand the stages for processing big data\nmin\nUse Azure Data Lake Storage Gen2 in data analytics workloads\nmin\nKnowledge check\nmin\nSummary\nmin\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Summary - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/introduction-to-data-engineering-azure/7-summary",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nSummary\n3 minutes\n\nData engineering is a well established industry role that is supported by multiple services in Microsoft Azure. Data engineers can use these services to work with different types of data, building integration, transformation, and consolidation solutions to support enterprise analytics.\n\n Tip\n\nTo learn more about Azure architecture solutions for data analytics, see Analytics architecture design.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Knowledge check - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/introduction-to-data-engineering-azure/6-knowledge-check",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nKnowledge check\n3 minutes\n\nChoose the best response for each of the questions, then select Check your answers.\n\n1. \n\nData in a relational database table is…\n\n \n\nStructured\n\nSemi-structured\n\nUnstructured\n\n2. \n\nIn a data lake, data is stored in?\n\n \n\nRelational tables\n\nFiles\n\nA single JSON document\n\n3. \n\nWhich of the following Azure services provides capabilities for running data pipelines AND managing analytical data in a data lake or relational data warehouse?\n\n \n\nAzure Stream Analytics\n\nAzure Synapse Analytics\n\nAzure Databricks\n\nCheck your answers\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Data engineering in Microsoft Azure - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/introduction-to-data-engineering-azure/5-common-tooling-azure-data-engineering",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nData engineering in Microsoft Azure\n6 minutes\n\nMicrosoft Azure includes many services that can be used to implement and manage data engineering workloads.\n\nThe diagram displays the flow from left to right of a typical enterprise data analytics solution, including some of the key Azure services that may be used. Operational data is generated by applications and devices and stored in Azure data storage services such as Azure SQL Database, Azure Cosmos DB, and Microsoft Dataverse. Streaming data is captured in event broker services such as Azure Event Hubs.\n\nThis operational data must be captured, ingested, and consolidated into analytical stores; from where it can be modeled and visualized in reports and dashboards. These tasks represent the core area of responsibility for the data engineer. The core Azure technologies used to implement data engineering workloads include:\n\nAzure Synapse Analytics\nAzure Data Lake Storage Gen2\nAzure Stream Analytics\nAzure Data Factory\nAzure Databricks\n\nThe analytical data stores that are populated with data produced by data engineering workloads support data modeling and visualization for reporting and analysis, often using sophisticated visualization tools such as Microsoft Power BI.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Important data engineering concepts - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/introduction-to-data-engineering-azure/4-common-patterns-azure-data-engineering",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nImportant data engineering concepts\n6 minutes\n\nThere are some core concepts with which data engineers should be familiar. These concepts underpin many of the workloads that data engineers must implement and support.\n\nOperational and analytical data\n\nOperational data is usually transactional data that is generated and stored by applications, often in a relational or non-relational database. Analytical data is data that has been optimized for analysis and reporting, often in a data warehouse.\n\nOne of the core responsibilities of a data engineer is to design, implement, and manage solutions that integrate operational and analytical data sources or extract operational data from multiple systems, transform it into appropriate structures for analytics, and load it into an analytical data store (usually referred to as ETL solutions).\n\nStreaming data\n\nStreaming data refers to perpetual sources of data that generate data values in real-time, often relating to specific events. Common sources of streaming data include internet-of-things (IoT) devices and social media feeds.\n\nData engineers often need to implement solutions that capture real-time stream of data and ingest them into analytical data systems, often combining the real-time data with other application data that is processed in batches.\n\nData pipelines\n\nData pipelines are used to orchestrate activities that transfer and transform data. Pipelines are the primary way in which data engineers implement repeatable extract, transform, and load (ETL) solutions that can be triggered based on a schedule or in response to events.\n\nData lakes\n\nA data lake is a storage repository that holds large amounts of data in native, raw formats. Data lake stores are optimized for scaling to massive volumes (terabytes or petabytes) of data. The data typically comes from multiple heterogeneous sources, and may be structured, semi-structured, or unstructured.\n\nThe idea with a data lake is to store everything in its original, untransformed state. This approach differs from a traditional data warehouse, which transforms and processes the data at the time of ingestion.\n\nData warehouses\n\nA data warehouse is a centralized repository of integrated data from one or more disparate sources. Data warehouses store current and historical data in relational tables that are organized into a schema that optimizes performance for analytical queries.\n\nData engineers are responsible for designing and implementing relational data warehouses, and managing regular data loads into tables.\n\nApache Spark\n\nApache Spark is a parallel processing framework that takes advantage of in-memory processing and a distributed file storage. It's a common open-source software (OSS) tool for big data scenarios.\n\nData engineers need to be proficient with Spark, using notebooks and other code artifacts to process data in a data lake and prepare it for modeling and analysis.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "What is data engineering - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/introduction-to-data-engineering-azure/2-what-data-engineering",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nWhat is data engineering\n5 minutes\n\nThe data engineer will often work with multiple types of data to perform many operations using many scripting or coding languages that are appropriate to their individual organization.\n\nTypes of data\n\nThere are three primary types of data that a data engineer will work with.\n\nExpand table\nStructured\tSemi-structured\tUnstructured\n\t\t\nStructured data primarily comes from table-based source systems such as a relational database or from a flat file such as a comma separated (CSV) file. The primary element of a structured file is that the rows and columns are aligned consistently throughout the file.\tSemi-structured data is data such as JavaScript object notation (JSON) files, which may require flattening prior to loading into your source system. When flattened, this data doesn't have to fit neatly into a table structure.\tUnstructured data includes data stored as key-value pairs that don't adhere to standard relational models and Other types of unstructured data that are commonly used include portable data format (PDF), word processor documents, and images.\nData operations\n\nAs a data engineer some of the main tasks that you'll perform in Azure include data integration, data transformation, and data consolidation.\n\nData integration\n\nData Integration involves establishing links between operational and analytical services and data sources to enable secure, reliable access to data across multiple systems. For example, a business process might rely on data that is spread across multiple systems, and a data engineer is required to establish links so that the required data can be extracted from all of these systems.\n\nData transformation\n\nOperational data usually needs to be transformed into suitable structure and format for analysis, often as part of an extract, transform, and load (ETL) process; though increasingly a variation in which you extract, load, and transform (ELT) the data is used to quickly ingest the data into a data lake and then apply \"big data\" processing techniques to transform it. Regardless of the approach used, the data is prepared to support downstream analytical needs.\n\nData consolidation\n\nData consolidation is the process of combining data that has been extracted from multiple data sources into a consistent structure - usually to support analytics and reporting. Commonly, data from operational systems is extracted, transformed, and loaded into analytical stores such as a data lake or data warehouse.\n\nCommon languages\n\nData Engineers must be proficient with a range of tools and scripting languages - in particular SQL and Python, and potentially others.\n\nSQL - One of the most common languages data engineers use is SQL, or Structured Query Language, which is a relatively easy language to learn. SQL uses queries that include SELECT, INSERT, UPDATE, and DELETE statements to directly work with the data stored in tables.\n\nPython - Python is one of the most popular and fastest growing programming languages in the world. It's used for all sorts of tasks, including web programming and data analysis. It has emerged as the language to learn for machine learning, and is increasing in popularity in data engineering with the use of notebooks.\n\nOthers - Depending upon the needs of the organization and your individual skill set, you may also use other popular languages within or outside of notebooks including R, Java, Scala, .NET, and more. The use of notebooks is growing in popularity, and allows collaboration using different languages within the same notebook.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Introduction - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/introduction-to-data-engineering-azure/1-introduction",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nAdd\nIntroduction\n3 minutes\n\nIn most organizations, a data engineer is the primary role responsible for integrating, transforming, and consolidating data from various structured and unstructured data systems into structures that are suitable for building analytics solutions. An Azure data engineer also helps ensure that data pipelines and data stores are high-performing, efficient, organized, and reliable, given a specific set of business requirements and constraints.\n\nNeed help? See our troubleshooting guide or provide specific feedback by reporting an issue.\n\nFeedback\n\nWas this page helpful?\n\nYes\nNo\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  },
  {
    "title": "Introduction to data engineering on Azure - Training | Microsoft Learn",
    "url": "https://learn.microsoft.com/en-us/training/modules/introduction-to-data-engineering-azure/",
    "html": "Skip to main content\n\tWe use optional cookies to improve your experience on our websites, such as through social media connections, and to display personalized advertising based on your online activity. If you reject optional cookies, only cookies necessary to provide you the services will be used. You may change your selection by clicking “Manage Cookies” at the bottom of the page. Privacy Statement Third-Party Cookies\nAccept Reject Manage cookies\nLearn\nDocumentation\nTraining\nCredentials\nQ&A\nCode Samples\nAssessments\nShows\nSign in\nTraining\nProducts\nCareer Paths\nBrowse all training\nEducator Center\nStudent Hub\nFAQ & Help\nIntroduction to data engineering on Azure\nModule\n6 Units\nFeedback\nIntermediate\nData Engineer\nAzure\n\nMicrosoft Azure provides a comprehensive platform for data engineering; but what is data engineering? Complete this module to find out.\n\nLearning objectives\n\nIn this module you will learn how to:\n\nIdentify common data engineering tasks\nDescribe common data engineering concepts\nIdentify Azure services for data engineering\nAdd\nPrerequisites\n\nBefore starting this module, you should have completed the Microsoft Azure Data Fundamentals certification or have equivalent knowledge and experience.\n\nIntroduction\nmin\nWhat is data engineering\nmin\nImportant data engineering concepts\nmin\nData engineering in Microsoft Azure\nmin\nKnowledge check\nmin\nSummary\nmin\nEnglish (United States)\nYour Privacy Choices\nTheme\nManage cookies\nPrevious Versions\nBlog\nContribute\nPrivacy\nTerms of Use\nTrademarks\n© Microsoft 2023"
  }
]